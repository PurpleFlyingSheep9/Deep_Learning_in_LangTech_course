{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "laser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyOaLSEUNSmi50ouY9BZtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/laser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znqBFEp7wtzP",
        "colab_type": "code",
        "outputId": "a0738b09-675c-46be-de6d-8ea965abda6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: laserembeddings in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: transliterate==1.10.2 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (1.10.2)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (1.4.0)\n",
            "Requirement already satisfied: subword-nmt<0.4.0,>=0.3.6 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (0.3.7)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (1.18.2)\n",
            "Requirement already satisfied: sacremoses==0.0.35 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (0.0.35)\n",
            "Requirement already satisfied: six>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from transliterate==1.10.2->laserembeddings) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->laserembeddings) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.38.0)\n",
            "Downloading models into /usr/local/lib/python3.6/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzDKFfi4wWfz",
        "colab_type": "code",
        "outputId": "bf515d3c-19c9-4131-ecaf-ac67e102b34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from laserembeddings import Laser\n",
        "\n",
        "laser = Laser()\n",
        "#can this be any simpler? :)\n",
        "embeddings = laser.embed_sentences(['I love pasta.',\"J'adore les pâtes.\",'Ich liebe Pasta.'],lang=['en', 'fr', 'de'])\n",
        "\n",
        "print(embeddings)\n",
        "print(embeddings.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-5.2039034e-04 -2.8321798e-05 -1.6871556e-04 ...  3.4788880e-03\n",
            "  -1.9968916e-03  8.1148157e-03]\n",
            " [ 3.2193225e-03 -9.9815712e-05  5.9067454e-05 ...  7.6490263e-03\n",
            "   1.1962595e-03  2.4502855e-03]\n",
            " [ 5.3412135e-04 -3.6210098e-05 -1.4794555e-04 ...  6.1386474e-03\n",
            "  -1.6569832e-03  6.3126395e-03]]\n",
            "(3, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR2aTnaXyIRv",
        "colab_type": "text"
      },
      "source": [
        "# Test the embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC1ygwtO7H7W",
        "colab_type": "text"
      },
      "source": [
        "* We are working on a paraphrase corpus, from which I borrowed some early data\n",
        "* The two files below `yle.txt` and `hs.txt` contain some 200+ news titles from YLE and HS, judged by a human to be paraphrases or near-paraphrases of each other\n",
        "* The selection is such that lexical overlap is minimized\n",
        "* The two files are line-aligned\n",
        "* We could make a simple test of LASER, comparing them against each other to see if we can pair these up\n",
        "* In other words: for every HS title, find the nearest YLE title\n",
        "* Measure how often it is correct\n",
        "* Random baseline is roughly 1/200, i.e. about 0.5%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVSHlFY06osU",
        "colab_type": "code",
        "outputId": "582728a2-8351-4ed4-c10d-ea77fbd6422b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!wget -nc http://dl.turkunlp.org/.ginter/hs.txt\n",
        "!wget -nc http://dl.turkunlp.org/.ginter/yle.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘hs.txt’ already there; not retrieving.\n",
            "\n",
            "File ‘yle.txt’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB0qsYL59l5R",
        "colab_type": "code",
        "outputId": "49210214-7da7-4e3d-812d-c0683389bf69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def read_file(fname):\n",
        "  lines=[]\n",
        "  with open(fname) as f:\n",
        "    for line in f:\n",
        "      line=line.strip()\n",
        "      if not line:\n",
        "        continue\n",
        "      lines.append(line)\n",
        "  return lines\n",
        "\n",
        "hs=read_file(\"hs.txt\")\n",
        "yle=read_file(\"yle.txt\")\n",
        "\n",
        "hs_vectors=laser.embed_sentences(hs,\"fi\")\n",
        "yle_vectors=laser.embed_sentences(yle,\"fi\")\n",
        "\n",
        "print(\"hs\",hs_vectors.shape)\n",
        "print(\"yle\",yle_vectors.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hs (217, 1024)\n",
            "yle (217, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ47PYIO-PRS",
        "colab_type": "code",
        "outputId": "d27b6915-fdb6-4e12-c111-8fee9e481c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sklearn.metrics\n",
        "# Given two sets of vectors, this function calculates all-pair cosine distances\n",
        "all_dist=sklearn.metrics.pairwise_distances(hs_vectors,yle_vectors)\n",
        "print(\"Distance matrix shape:\", all_dist.shape)\n",
        "#we get a sentence-by-sentence matrix, with distances"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance matrix shape: (217, 217)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WOy2wU9-6XO",
        "colab_type": "code",
        "outputId": "bc875db1-020c-4d05-d0c5-8878cd4220ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "#Calculate for every row the document with minimal distance in that row (axis=-1 means minimum along the last axis)\n",
        "nearest=all_dist.argmin(axis=-1) #These are the nearest neighbors for each HS title (indices into YLE), perfect solution would be [0,1,2,3...,216]\n",
        "print(nearest)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[121   1   1   3 120 116   6   9   8   9 177  11 102  13  44  15 126  17\n",
            " 196 206 189  96  22  23  70   9  77 189 216  67  30 136  78  61  34  74\n",
            "  53  37 161  39  40 147 203  13  44  45   9  47  48  49  14  51 120  53\n",
            "  54  55 121  46  58 123  60  61 189  48  64  65  39  13 126  69  70  71\n",
            "  61  73  74  61  76  26 189  74  14  81  82  83  84  85  86  87 182  64\n",
            "  15 135 176 189  70  59 206  97 208  99  99  84 102 103 104 105  48  67\n",
            "  91 175 110  14 112 113  39 115 116 121 118  73 120 121 121 123 124 125\n",
            " 126 159 128 129 130  92 132 133 134  61 136 137 138   9  39 141 142 123\n",
            "  39   9  35  15 150 149  67 151 152 153 180 155 156 137 158  79 160 176\n",
            "  79 163 164 112  39 167 168 169 132 171 172 146  61 175 201 177 178 179\n",
            " 180  63 189 183 184  67  39 187 197 189  94 146 192 193 150 195 196 197\n",
            "  78  39 198  74 202 203 204 133 206   9 208 146  86  59  30 213 214 215\n",
            " 216]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvwQGUKY_akG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's package this all nicely into a function\n",
        "import random\n",
        "\n",
        "def eval_embeddings(texts1,texts2,vectors1,vectors2):\n",
        "  assert len(texts1)==len(texts2), \"We assume aligned data\"\n",
        "  all_dist=sklearn.metrics.pairwise_distances(vectors1,vectors2)\n",
        "  nearest=all_dist.argmin(axis=-1) #These are the nearest neighbors for each HS title (indices into YLE), perfect solution would be [0,1,2,3...,216]   \n",
        "  correct=[] #Let's put here the correct pairs\n",
        "  incorrect=[] #Let's put here the incorrect pairs\n",
        "  for i,txt1 in enumerate(texts1):\n",
        "    j=nearest[i] #the index at which the nearest sentence is\n",
        "    txt2=texts2[j] #..and its text\n",
        "    if i==j:\n",
        "      #This is correct\n",
        "      correct.append((txt1,txt2))\n",
        "    else:\n",
        "      incorrect.append((txt1,txt2))\n",
        "\n",
        "  print(f\"Correct {len(correct)}/{len(texts1)}={len(correct)/len(texts1)*100}%\") #these f-strings are really neat, you can embed expressions and have them printed\n",
        "  random.shuffle(correct)\n",
        "  random.shuffle(incorrect)\n",
        "  print(\"\\n\\n---------- Sample of correct ones:\")\n",
        "  for t1,t2 in correct[:15]:\n",
        "    print(t1)\n",
        "    print(t2)\n",
        "    print()\n",
        "  print(\"\\n\\n---------- Sample of incorrect ones:\\n\")\n",
        "  for t1,t2 in incorrect[:15]:\n",
        "    print(t1)\n",
        "    print(t2)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzFwrTZUCWMs",
        "colab_type": "code",
        "outputId": "52cbcba5-4dea-4857-a70b-eed54ae30c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_embeddings(hs,yle,hs_vectors,yle_vectors)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct 110/217=50.69124423963134%\n",
            "\n",
            "\n",
            "---------- Sample of correct ones:\n",
            "Tutkimus: Lapsen riski sairastua astmaan on sitä pienempi, mitä enemmän kotona on bakteereja\n",
            "Kodin sisäilman mikrobisto voi suojella lasta astmalta\n",
            "\n",
            "Lännen Media: EU ei myönnä kriisiapua maatalouden kuivuus­ongelmaan, koska rahaa sen hoitamiseen ei ole\n",
            "Euroopan unionilta ei ole tulossa kriisitukea maataloudelle\n",
            "\n",
            "Presidentti Niinistö leikattu Jorvin sairaalassa – Toimenpide sujui hyvin, potilas on jo kotiutettu\n",
            "Presidentti Niinistö pääsi päiväkirurgisesta leikkauksesta – viikon matkustuskielto\n",
            "\n",
            "Varas ajoi holtittomasti läpi Töölön – Pakomatkalla kolhittiin pahoin kuutta autoa ja jalankulkijat olivat vaarassa jäädä alle\n",
            "Hurja takaa-ajo Helsingissä – lapsi työnnettiin kumoon kassajonossa, jalankulkijat hyppivät sivuun poliisia paenneen auton tieltä\n",
            "\n",
            "Pääministeri Sipilä Oulun epäillystä seksuaali­rikoksesta: ”Oikeusvaltiossa syylliset saavat rangaistuksen etnisyydestä riippumatta”\n",
            "Pääministeri Sipilä Oulun raiskausepäilyistä: \"Epäinhimillinen teko, jonka pahuutta ei voi käsittää\"\n",
            "\n",
            "Yli tuhannella potilaalla vääriä lääkelistoja – potilastietojärjestelmä Lifecaressa uusi vika: ”Tilanne on äärimmäisen vakava”\n",
            "Potilasturvallisuus vaarassa – tietojärjestelmästä löytyi taas vika Päijät-Hämeessä\n",
            "\n",
            "Kolme ihmistä kuoli hallituksen vastaisissa mielenosoituksissa Kolumbiassa, sadattuhannet protestoijat vaativat turvaa\n",
            "Kolumbiassa mielenosoittajat vastustavat hallitusta suurprotesteissa – Korruptio, huumekauppa ja toimeentulo huolestuttavat kansaa\n",
            "\n",
            "Antibiooteille vastustuskykyinen bakteeri on yleistynyt suomalaisilla sioilla, Työterveys­laitos kehottaa suojautumaan\n",
            "Ärhäkkä bakteeri riivaa suomalaisia sikoja – ei tartu kypsästä lihasta, mutta leikkuulautojen pesu on tärkeää\n",
            "\n",
            "Perussuomalaisilla nuorilla kesäkuuhun asti aikaa selittää twiittiään: Valtionapu saatetaan periä takaisin\n",
            "PS-Nuorten valtionapu vaakalaudalla, ministeriö perää järjestöltä selvitystä\n",
            "\n",
            "Vetoomustuomioistuin: Trump ei voi estää eri mieltä olevia seuraamasta Twitter-tiliään\n",
            "Yhdysvaltalainen tuomioistuin: Trumpin Twitter-blokkaukset ovat perustuslain vastaista toimintaa\n",
            "\n",
            "Eduskuntapuolueilta yhteinen vetoomus kansalaisille: Olkaa tarkkana vale­uutisten suhteen\n",
            "9 puolueelta yhteinen kannanotto: Vaalihäirintä uhkaa demokratiaa – tärkeää, että äänestäjät tunnistavat valeuutisoinnin\n",
            "\n",
            "Pankin työntekijän epäillään kavaltaneen satoja tuhansia euroja Länsi-Uudellamaalla\n",
            "Poliisi: Säästöpankin työntekijä myönsi 350 000 euron kavalluksen – siirtyy syyteharkintaan\n",
            "\n",
            "Kaupunginvaltuusto saa pohdittavakseen aloitteen Havis Amandan siirrosta\n",
            "Mantan patsaan siirrosta puuhataan Helsingissä valtuustoaloitetta\n",
            "\n",
            "Putinin tiedottajan tyttären harjoittelu Euroopan parlamentissa herättää epäilyjä ranskalaisen euro­edustajan lojaaliudesta, sanoo Liisa Jaakonsaari\n",
            "Putinin tiedottajan tytär on harjoittelussa Euroopan parlamentissa –  salaiset tiedot käytettävissä?\n",
            "\n",
            "Ruisrockin epäonni jatkuu: Migosin piti korvata keikkansa perunut pääesiintyjä, mutta trio jäi jumiin lentokentälle\n",
            "Jo toiset oharit Ruisrockille! – Travis Scottin tuuraajaksi kiinnitetyn hiphop-trion keikka peruuntui\n",
            "\n",
            "\n",
            "\n",
            "---------- Sample of incorrect ones:\n",
            "\n",
            "Vain joka neljäs yli 30-vuotias suomalainen on enää normaali­painoinen\n",
            "Pakolaisten määrä korkeimmillaan liki 70 vuoteen – kodistaan paenneita on jo yli 70 miljoonaa\n",
            "\n",
            "Selvitys: Toimittaja joutuu nettihäirinnän kohteeksi, jos hän kirjoittaa tietyistä aiheista – tai jos hän on joutunut äärioikeiston silmätikuksi\n",
            "Mies kuoli huippunopeustapahtumassa – Onnettomuustutkintakeskus ei tutki onnettomuutta: \"Kyseessä on extreme-laji\"\n",
            "\n",
            "Oikeus: Alkoholin nettimyynti ei ollut laitonta, suomalaismiehen syytteet nurin Helsingin käräjäoikeudessa\n",
            "Asvaltti- ja pihaurakoita tehnyt yhtiö jätti verot maksamatta –  irlantilainen osakas etsintäkuulutettu\n",
            "\n",
            "Suositusta olkapää­leikkauksesta pitäisi luopua kokonaan, sanovat asiantuntijat – osa kirurgeista uskoo yhä turhaksi todistetun toimen­piteen hyötyyn\n",
            "Tutkijat loivat sarvikuonoalkioita – Koeputkihedelmöitys tuo toivoa lajille, jota jäljellä vain kaksi naarasta\n",
            "\n",
            "Ukkosen aiheuttama vika häiritsi tiistaina junaliikennettä Etelä-Karjalassa, kaukojunia korvattiin busseilla\n",
            "Junaliikenne keskeytyi Luumäki–Vainikkala-välillä\n",
            "\n",
            "Suomen talous porskuttaa teollisuuden vetämänä – ”Tahti on piristynyt taas vaisumman syksyn jälkeen”\n",
            "Suomen bruttokansantuote tuo valoa marraskuun pimeyteen: Ekonomisti: \"Kasvu on kiihtynyt huimasti\"\n",
            "\n",
            "Kaksi kuolonuhria vaatineiden autokisojen turvallisuudesta löytyi merkittäviä puutteita – Pohjanmaa-rallissa katsojat saivat valita paikkansa lähestulkoon vapaasti\n",
            "Kaksi kaaharia hurjasteli Tuusulanväylällä rajua ylinopeutta – poliisin edellä yli 180 km/h\n",
            "\n",
            "EU:n ja Yhdysvaltain kauppasuhteet kiristyvät, USA on asettanut tulleja yli 6,7 miljardin euron arvoiselle tuonnille EU:sta\n",
            "Alkoholin etämyynnistä tänään ratkaisu käräjiltä, suomalaismiehen syytetään välttäneen veroja liki 1,7 miljoonan euron edestä\n",
            "\n",
            "VR:n lipun­myynnin tekninen vika on nyt korjattu\n",
            "Aseluvan verkkohaku lykkääntyy jo toistamiseen\n",
            "\n",
            "Opiskelijoille löytyi selvityksessä ihanneansio – Tuhannen euron yläpuolella tilanne muuttuu ja pänttäämisestä tulee kannattavampaa\n",
            "Suomi kiinnostaa ulkomaalaisia opiskelijoita, vaikka opiskelusta tuli maksullista – hakijamäärät ovat jälleen reippaassa nousussa\n",
            "\n",
            "Useilla pankeilla oli sunnuntaina vakavia yhteysongelmia – palvelut palautuivat käyttöön alkuillasta\n",
            "Vientialojen laajat lakot alkavat maanantaina – neuvotteluissa ei edistytty\n",
            "\n",
            "Naisen astma puhkeaa usein vasta aikuisena, tutkijan mukaan merkittävin riski­tekijä on suku­tausta\n",
            "Tutkijat loivat sarvikuonoalkioita – Koeputkihedelmöitys tuo toivoa lajille, jota jäljellä vain kaksi naarasta\n",
            "\n",
            "Näiden 11 kysymyksen pohjalta Sdp alkaa rakentaa hallitusta\n",
            "PS-Nuorten valtionapu vaakalaudalla, ministeriö perää järjestöltä selvitystä\n",
            "\n",
            "Vienti­alojen lakot alkoivat: Mukana jopa 100 000 työntekijää, taloudelliset menetykset nousevat arviolta 400 miljoonaan\n",
            "Posti muuttaa noin 700 paketti- ja verkkokauppatyöntekijän työehtoja – pohjapalkka pienenee, tuottavuudesta palkitaan\n",
            "\n",
            "Maksuttomuus nosti viisi­vuotiaiden osallistumista varhais­kasvatukseen parilla prosentti­yksiköllä\n",
            "Konstaapeli löi putka-asiakkaan pään vastaanottotiskiin – pidätettiin virantoimituksesta kahdeksi kuukaudeksi\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRvwS7HqT8-9",
        "colab_type": "text"
      },
      "source": [
        "# Try with BERT?\n",
        "\n",
        "*   We could try with BERT\n",
        "*   Test the [CLS] token as the sentence embedding\n",
        "*   Test the average of token embeddings as the sentence embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLEW-5WMCfjQ",
        "colab_type": "code",
        "outputId": "52a8e0a9-8ad8-4a0e-c0e4-de079347ba82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Note: since LASER is torch, maybe we continue in torch for the fun of it? :) (and you also asked for some torch examples)\n",
        "!pip install transformers\n",
        "import transformers\n",
        "\n",
        "bert_model = transformers.BertModel.from_pretrained(\"bert-base-finnish-cased-v1\") #models can be loaded by name from this list: https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L35\n",
        "bert_model = bert_model.cuda() #move the model to GPU\n",
        "bert_model.eval() #tell the model it will be used for predictions, not training (disables dropout for example)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(50105, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_12ElwHjDcks",
        "colab_type": "code",
        "outputId": "5b78df81-458b-4deb-bd30-c2431c55630a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "#Load the Finnish BERT tokenizer\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-finnish-cased-v1\") #also tokenizers can be loaded by nae\n",
        "\n",
        "def tokenize_texts(texts):\n",
        "  tokenized_ids=[tokenizer.encode(txt,add_special_tokens=True) for txt in texts] #this runs the BERT tokenizer, returns list of lists of integers\n",
        "  tokenized_ids_t=[torch.tensor(ids,dtype=torch.long) for ids in tokenized_ids] #turn lists of integers into torch tensors\n",
        "  tokenized_single_batch=torch.nn.utils.rnn.pad_sequence(tokenized_ids_t,batch_first=True) #zero-padding\n",
        "  return tokenized_single_batch\n",
        "\n",
        "hs_data=tokenize_texts(hs).cuda() #tokenize and move to GPU\n",
        "yle_data=tokenize_texts(yle).cuda()\n",
        "\n",
        "print(hs_data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([217, 37])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJdcSQNcI_It",
        "colab_type": "code",
        "outputId": "f4bb72b5-b65d-46a0-8893-6501315e6595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#This is how you run BERT in torch\n",
        "data=hs_data\n",
        "with torch.no_grad(): #tell the model not to gather gradients since we are evaluating, not training, saves memory and troubles\n",
        "  emb=bert_model(data.cuda()) #applies the model and returns several things, we care about the first. Documentation: https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L648\n",
        "  print(emb[0].shape)  # word x sequence x embedding\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([217, 37, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnxKXs1OOFRL",
        "colab_type": "code",
        "outputId": "96c96d5c-abcd-47e4-a7a7-6cd81537214a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#Let's pack this into a nice function\n",
        "def embed(data,how_to_pool=\"CLS\"):\n",
        "  with torch.no_grad(): #tell the model not to gather gradients\n",
        "    emb=bert_model(data.cuda()) #runs BERT and returns several things, we care about the first\n",
        "    #emb[0]  # batch x word x embedding\n",
        "    if how_to_pool==\"AVG\":\n",
        "      pooled=emb[0].mean(1) #average along the word dimension (axis 1) -> pools the embeddings into one\n",
        "    elif how_to_pool==\"CLS\":\n",
        "      pooled=emb[0][:,0,:].squeeze() #Pick the first token as the embedding\n",
        "    else:\n",
        "      assert False, \"how_to_pool should be CLS or AVG\"\n",
        "    print(\"Pooled shape:\",pooled.shape)\n",
        "  return pooled.cpu().numpy() #done! move data back to CPU and extract the numpy array\n",
        "\n",
        "hs_emb_cls=embed(hs_data,\"CLS\")\n",
        "yle_emb_cls=embed(yle_data,\"CLS\")\n",
        "\n",
        "hs_emb_avg=embed(hs_data,\"AVG\")\n",
        "yle_emb_avg=embed(yle_data,\"AVG\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pooled shape: torch.Size([217, 768])\n",
            "Pooled shape: torch.Size([217, 768])\n",
            "Pooled shape: torch.Size([217, 768])\n",
            "Pooled shape: torch.Size([217, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmEMNsMIV2vt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IVtrzrp_Nh4",
        "colab_type": "code",
        "outputId": "f38c6af6-e563-4971-99cb-e5632937d6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_embeddings(hs,yle,hs_emb_cls,yle_emb_cls)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct 25/217=11.52073732718894%\n",
            "\n",
            "\n",
            "---------- Sample of correct ones:\n",
            "Nordea sai uuden konserni­johtajan, kurssi nousussa – Suuromistaja Gardell vaatii kannattavuuden parantamista nopeasti ja ”dramaattisesti”\n",
            "Nordea löysi omistaan uuden konsernijohtajan – Frank Vang-Jensen aloittaa tehtävässä jo tänään\n",
            "\n",
            "Etla: Työpaikan menetys lisää ihmisen muutto­alttiutta\n",
            "Etlan tutkimus: Työttömyys pistää muuttokuorman herkästi liikkeeseen\n",
            "\n",
            "Li Andersson toivoo opetusministerin salkkua, sisäministerin paikka menossa vihreille – Tämä tiedetään salkkujaosta\n",
            "Vuorossa salkkujako – puolueiden puheenjohtajat koolle ratkomaan ministeripaikkoja\n",
            "\n",
            "Palvelunesto­hyökkäys on kaatanut esimerkiksi poliisin ja Verohallinnon verkko­sivut\n",
            "Poliisin ja Verohallinnon verkkosivuilla on taas häiriöitä – syy ei vielä tiedossa\n",
            "\n",
            "Tutkimus: 90 prosenttia Suomessa asuvista somaleista kokee tulevansa syrjityksi työmarkkinoilla\n",
            "Pääkaupunkiseudun maahanmuuttajat kokevat kuuluvansa suomalaiseen yhteiskuntaan, mutta suomalainen identiteetti on vain harvoilla\n",
            "\n",
            "Kodit kylmenneet aamulla pitkin Helsinkiä, kaukolämpöputkesta ryöppysi tulikuumaa vettä Uudenmaan­kadulle\n",
            "Tulikuumaa vettä pulppuaa Helsingin Uudenmaankadulle, alueen asukkaita varoitetaan\n",
            "\n",
            "EU-virkamiehiä pyydetty välttämään Finnairin lentoja niiden kalleuden takia –  Miksi Brysselistä pääsee Tukholmaan 200 euroa halvemmalla kuin Helsinkiin?\n",
            "EU kehottaa virkamiehiään välttämään Finnairia budjettisyistä – Finnairin lennot voivat maksaa moninkertaisesti kilpailijoihin verrattuna\n",
            "\n",
            "Poliisi saanut useita kymmeniä uusia vihjeitä liittyen lasten törkeistä hyväksikäytöistä epäiltyyn ”Enoon”: Joukossa mahdollisia uhreja\n",
            "Poliisi epäilee \"Enoksi\" kutsuttua miestä useista lapseen kohdistuneista seksuaalirikoksista Helsingissä – ainakin 12 uhria\n",
            "\n",
            "Vienti­alojen lakot alkoivat: Mukana jopa 100 000 työntekijää, taloudelliset menetykset nousevat arviolta 400 miljoonaan\n",
            "Vientialojen laajat lakot alkavat maanantaina – neuvotteluissa ei edistytty\n",
            "\n",
            "Yhdysvaltalaistuomari tukee demokraattien tietopyyntöä Trumpin aiemmista liiketoimista\n",
            "Trumpille takaisku taistelussa tulotietojen julkistamisesta\n",
            "\n",
            "Pääministeri Sipilä Oulun epäillystä seksuaali­rikoksesta: ”Oikeusvaltiossa syylliset saavat rangaistuksen etnisyydestä riippumatta”\n",
            "Pääministeri Sipilä Oulun raiskausepäilyistä: \"Epäinhimillinen teko, jonka pahuutta ei voi käsittää\"\n",
            "\n",
            "Keskon autoliikkeiden yt-neuvottelut päättyivät: työpaikkansa menettää 100 henkeä\n",
            "K-Auto ja K-Caara irtisanovat sata työntekijää\n",
            "\n",
            "Tuore kysely paljastaa nuorten puhelin­riippuvuuden: ”On ärsyttävää, kun kaverin kanssa ei keksi enää mitään tekemistä”\n",
            "Nuoret pyrkivät vähentämään puhelimen käyttöä: \"On ärsyttävää, kun kaverin kanssa ei keksi enää mitään tekemistä\"\n",
            "\n",
            "Tutkimus: Suomalaiset kuuluvat maailman tiede­myönteisimpiin kansoihin\n",
            "Suomalaisten luotto tieteeseen on vankka\n",
            "\n",
            "Sadat riskitarkastukset hoivakoteihin ovat paljastaneet kymmeniä vakavia puutteita, mutta myös moitteettomia yksiköitä\n",
            "Vanhusten hoitokoteihin on tehty satoja tarkastuksia – erittäin vakavia tapauksia löytynyt joitakin kymmeniä\n",
            "\n",
            "\n",
            "\n",
            "---------- Sample of incorrect ones:\n",
            "\n",
            "Työleirille karkotetuksi huhuttu Pohjois-Korean neuvottelija palasi parrasvaloihin\n",
            "Kemiallisten aseiden tutkijat aikovat nostaa Duman uhreja haudoista näytteitä varten\n",
            "\n",
            "Eduskuntapuolueilta yhteinen vetoomus kansalaisille: Olkaa tarkkana vale­uutisten suhteen\n",
            "THL: Sadattuhannet suomalaiset altistuvat liikennemelulle\n",
            "\n",
            "Muuttovalmiit valmistalot ohittivat suosiossa perinteiset talopaketit\n",
            "Etlan tutkimus: Työttömyys pistää muuttokuorman herkästi liikkeeseen\n",
            "\n",
            "Ukkosen aiheuttama vika häiritsi tiistaina junaliikennettä Etelä-Karjalassa, kaukojunia korvattiin busseilla\n",
            "Tulikuumaa vettä pulppuaa Helsingin Uudenmaankadulle, alueen asukkaita varoitetaan\n",
            "\n",
            "Brexit-neuvottelut konservatiivien ja työväen­puolueen välillä katkesivat, Mayn lähtölaskenta alkoi\n",
            "Kunnallisveroa saattaa korottaa 80–90 kuntaa – paineita myös suurissa kaupungeissa\n",
            "\n",
            "Oluiden ja mietojen viinien matkustajatuonti lisääntyi, väkevien tuonti väheni\n",
            "Kaksi miestä tappeli kokkiveitsillä, toinen kuoli sairaalassa\n",
            "\n",
            "Mansikkahuijauksia aletaan suitsia kemian keinoin: Isotooppi­analyysi paljastaa marjan alkuperän\n",
            "Miehen epäillään kähmineen ja lyöneen lasta Turun Puutorilla – poliisi pyytää havaintoja\n",
            "\n",
            "Eduskunnassa suullinen kysely­tunti, sen jälkeen keskustellaan pysyvää kesäaikaa ehdottavasta kansalais­aloitteesta – suora lähetys juuri nyt\n",
            "Ryhmäjohtaja Jokinen korjaa sanomisiaan: Kokoomus esittelee sote-mallinsa, aikataulu vielä auki\n",
            "\n",
            "TV2:n Uusi päivä -sarjan lopettaminen vie työn monelta näyttelijältä\n",
            "Meyer Turun telakalle uusi risteilylaivatilaus\n",
            "\n",
            "Tavallista pidempään vaikuttava parasetamol-lääke kielletään EU:n alueella – Ruotsissa sattunut kymmeniä yliannostuksia\n",
            "Poliisi: Suomessa paljastuneet kokaiinin konttisalakuljetusyritykset merkki muutoksesta Euroopan järjestäytyneessä rikollisuudessa\n",
            "\n",
            "Kolme iranilaista alusta yritti pysäyttää brittiläisen säiliö­aluksen Persian­lahdella, Britannia nostanut valmiustasoa\n",
            "Aseistautuneet hyökkääjät iskivät ministeriörakennukseen Kabulissa\n",
            "\n",
            "Suomen teollisuus­tuotanto kasvoi vauhdikkaammin kuin lähes vuoteen\n",
            "Oodi veti Helsingin kirjastot ennätyslukemiin\n",
            "\n",
            "Poliisi on lopettanut Oulun mahdollisen asemiehen etsinnät – Opiskelijat pääsivät kotiin iltapäivällä\n",
            "Yksi ihminen kuoli yksityisasunnossa Sipoossa sunnuntaina – Poliisi tutkii tapausta tappona\n",
            "\n",
            "Haavoittuvassa asemassa oleville turvapaikanhakijoille tarjotaan yksilöllistä apua\n",
            "Rallionnettomuudet johtavat uusiin turvallisuussuosituksiin\n",
            "\n",
            "Kuopion kouluhyökkääjää vaaditaan vangittavaksi epäiltynä murhasta ja yhdeksästä murhan yrityksestä\n",
            "Poliisi epäilee: Kaksi miestä kuoli salaman iskuun Juuassa\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OESxU6_V6ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6866351c-64f0-48e0-fbda-3cf6f2e9e8e7"
      },
      "source": [
        "eval_embeddings(hs,yle,hs_emb_avg,yle_emb_avg)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct 53/217=24.42396313364055%\n",
            "\n",
            "\n",
            "---------- Sample of correct ones:\n",
            "Ministeri Lindström pani nimensä paperiin, jonka merkitystä ei täysin ymmärtänyt – Päätös oli viedä Suomen valtion oikeuskamppailuun miljoonista euroista\n",
            "Ministeri Lindström oli vähällä viedä valtion miljoonakorvauksiin talousrikolliselle – \"Allekirjoitukseni saatiin viekkaudella\"\n",
            "\n",
            "Poliisi saanut useita kymmeniä uusia vihjeitä liittyen lasten törkeistä hyväksikäytöistä epäiltyyn ”Enoon”: Joukossa mahdollisia uhreja\n",
            "Poliisi epäilee \"Enoksi\" kutsuttua miestä useista lapseen kohdistuneista seksuaalirikoksista Helsingissä – ainakin 12 uhria\n",
            "\n",
            "Suositusta olkapää­leikkauksesta pitäisi luopua kokonaan, sanovat asiantuntijat – osa kirurgeista uskoo yhä turhaksi todistetun toimen­piteen hyötyyn\n",
            "Asiantuntijat: Olkapään avarrusleikkaukset ovat terveydenhuollon voimavarojen tuhlaamista – ei ole hyötyä kivusta kärsiville\n",
            "\n",
            "Suojelupoliisi osallistuu Airiston Helmen kotietsintä­aineiston tarkasteluun – valtava aineisto vastaa jopa 100 000 muisti­tikun sisältöä\n",
            "Poliisilla iso urakka edessä: Supo auttaa KRP:tä Turun saaristosta löytyneen materiaalin läpikäymisessä\n",
            "\n",
            "Etla: Työpaikan menetys lisää ihmisen muutto­alttiutta\n",
            "Etlan tutkimus: Työttömyys pistää muuttokuorman herkästi liikkeeseen\n",
            "\n",
            "Veitsellä kauppa­keskuksessa huitonutta miestä epäillään pahoinpitelyn yrityksestä ja laittomasta uhkauksesta\n",
            "Nuori mies riehui veitsen kanssa kauppakeskuksessa Joensuussa\n",
            "\n",
            "EU:n ja Yhdysvaltain kauppasuhteet kiristyvät, USA on asettanut tulleja yli 6,7 miljardin euron arvoiselle tuonnille EU:sta\n",
            "Yhdysvaltain ennätykselliset tullimaksut EU:lle astuivat voimaan – Listalla Airbusin lentokoneita, ranskalaisia viinejä ja skottilaisia viskejä\n",
            "\n",
            "Finnwatch arvostelee Danske Bankia: Pankki tiesi Viron konttorin rahanpesusta vuosia eikä maininnut niistä mitään vuosiraporteissaan\n",
            "Finnwatch: Pankeille sapiskaa puutteellisesta veroraportoinnista, ei viitteitä aggressiivisesta verosuunnittelusta\n",
            "\n",
            "Näin suomalaiset arvioivat Rinteen hallitusta – Keskustan Mika Lintilä saa enemmän kiitosta Sdp:n kannattajilta kuin omiltaan\n",
            "Rinteen hallitus saa HS-gallupissa melko neutraalin arvion tähänastisesta onnistumisestaan\n",
            "\n",
            "EU-virkamiehiä pyydetty välttämään Finnairin lentoja niiden kalleuden takia –  Miksi Brysselistä pääsee Tukholmaan 200 euroa halvemmalla kuin Helsinkiin?\n",
            "EU kehottaa virkamiehiään välttämään Finnairia budjettisyistä – Finnairin lennot voivat maksaa moninkertaisesti kilpailijoihin verrattuna\n",
            "\n",
            "Rakennusliitto perui yksittäisiin yhtiöihin suunniteltuja lakkoja – ”Paikallisista kahinoista siirrytään koko valtakunnan kattavaan taisteluun”\n",
            "Rakennusliitto perui työsulkua edeltävät lakot – Puheenjohtaja: \"Oli tarpeetonta pysäytellä tehtaita\"\n",
            "\n",
            "Patrik Leppänen, 22, ei totellut työnantajan käskyä ottaa Roosa nauha pois rinta­pielestään lento­aseman turva­tarkastuksessa ja sai potkut – ”Halusin osoittaa tukea äidilleni”\n",
            "Irtisanottu turvatarkastaja puolustaa tekoaan läheisensä  rintasyövällä, \"ei kaduta yhtään\" – Airpro: työntekijää varoitettu useasti\n",
            "\n",
            "Mediayhtiö Sanoma lähtee mukaan tapahtumabisnekseen – ostaa N.C.D. Productionilta festari-, konsertti- ja risteilyliiketoiminnan\n",
            "Sanoma rynnistää mukaan festaribisnekseen – osti muun muassa RMJ:n, Tammerfestin ja Suomipop-festivaalit\n",
            "\n",
            "Naistenklinikan synnytys- ja leikkaus­toiminta palautui normaaliksi – osastoille levinnyt tuli­palo olisi ”kauhu­skenaario”\n",
            "Naistenklinikan tulipalon alta evakuoitiin lähes 70 perhettä, palo vaikuttaa sairaalan toimintaan tänäänkin: synnyttäjät ohjataan muihin sairaaloihin\n",
            "\n",
            "Yle perustaa uuden yksikön tuottamaan suomenkielisiä tapahtumia ”uudistuakseen yhteiskunnan mukana”\n",
            "Yle uudistaa rakennettaan – Johtoryhmään uusia nimiä\n",
            "\n",
            "\n",
            "\n",
            "---------- Sample of incorrect ones:\n",
            "\n",
            "Ennennäkemätön huijaus­epäily Helsingin lääke­tieteellisen pääsy­kokeissa: Surkeasti vastanneen kokelaan papereihin ilmestyi mystisesti täydelliset vastaukset\n",
            "\"Toivotimme lapset tervetulleiksi\" – Perheille lähetetty, ilmaista päivähoitoa mainostanut kirje olikin yllättävän tehokas\n",
            "\n",
            "Useilla pankeilla oli sunnuntaina vakavia yhteysongelmia – palvelut palautuivat käyttöön alkuillasta\n",
            "Kunnallisveroa saattaa korottaa 80–90 kuntaa – paineita myös suurissa kaupungeissa\n",
            "\n",
            "Pankin työntekijän epäillään kavaltaneen satoja tuhansia euroja Länsi-Uudellamaalla\n",
            "Aseluvan verkkohaku lykkääntyy jo toistamiseen\n",
            "\n",
            "Häiriö Karjalan radan rautatieliikenteessä jatkuu myös maanantaiaamuna, osa yhteyksistä korvataan busseilla\n",
            "Tulikuumaa vettä pulppuaa Helsingin Uudenmaankadulle, alueen asukkaita varoitetaan\n",
            "\n",
            "Trump: Huawein tilanne voi ratketa osana Yhdysvaltojen ja Kiinan kauppaneuvotteluja\n",
            "USA:n puolustusvoimat julkaisi videon Isis-johtajan kuolemaan johtaneesta operaatiosta\n",
            "\n",
            "Taksilupien määrä on jopa kaksinkertaistunut isoissa kaupungeissa – kiistelty lakiuudistus on samanaikaisesti nostanut kyytien hintoja\n",
            "Vanhusten hoitokoteihin on tehty satoja tarkastuksia – erittäin vakavia tapauksia löytynyt joitakin kymmeniä\n",
            "\n",
            "IS ja IL: Varusmiespalvelusta suorittaneen naisen taposta epäiltynä on vangittu 24-vuotias mies\n",
            "Nainen sai syytteen taposta Laihialla – 60-vuotias nainen surmattiin vuosi sitten\n",
            "\n",
            "Sanoma ostaa hollantilaisen opetusalan yhtiön 277 miljoonalla\n",
            "Äänekoskelle 40 miljoonan koelaitos puupohjaisten tekstiilien valmistukseen\n",
            "\n",
            "USA julkaisi ensimmäiset kuvat ja videon hyökkäyksestä Isis-johtaja al-Baghdadin piilo­paikkaan, Isis nimitti uuden johtajan\n",
            "Kiinalainen nainen pidätettiin Trumpin klubilla Floridassa – sanoi osallistuvansa \"ystävyystapahtumaan\"\n",
            "\n",
            "Lännen Media: Lähes kaksi kolmasosaa suomalaisista tyytyväisiä Marinin hallitukseen\n",
            "Yle uudistaa rakennettaan – Johtoryhmään uusia nimiä\n",
            "\n",
            "Ylitorniolla ammuttiin junan matkustaja­vaunua haulikolla, poliisi kaipaa lisätietoja\n",
            "Kaksi miestä tappeli kokkiveitsillä, toinen kuoli sairaalassa\n",
            "\n",
            "Sairaanhoitaja­koulutukseen lisätään noin 180 uutta aloituspaikkaa\n",
            "Lennonjohtajat varoittavat työnseisausten sarjasta\n",
            "\n",
            "Kysely: Lähes puolet nuorista työntekijöistä ei saa pitää neljän viikon yhtäjaksoista lomaa\n",
            "Kauppalehti: Kanaravintolaketju KFC tulee Suomeen ensi vuonna\n",
            "\n",
            "Tutkijoiden läpimurto voi pelastaa sukupuuttoon kuolevan eläinlajin\n",
            "Lennonjohtajat varoittavat työnseisausten sarjasta\n",
            "\n",
            "Merenkulkua uhannut lakko peruuntuu\n",
            "Posti muuttaa palvelujaan tänään\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le84A4hyV7bx",
        "colab_type": "text"
      },
      "source": [
        "# What have we learned?\n",
        "\n",
        "* BERT [CLS] embedding is the worst\n",
        "* Average of BERT token embeddings comes then\n",
        "* LASER still doubles the numbers\n",
        "* What kind of intuitive insight one gets when looking at the correct and incorrect predictions? What does the model base its decisions on?\n",
        "\n"
      ]
    }
  ]
}