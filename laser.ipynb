{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "laser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvg7U640tw3mbuKQn8OI1J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "142dd5933d9c4499a538fa8a579a0338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d03ed22ae4384940a7d454af3716cc11",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c33af93fbaaa488b9741f2b9393b4b16",
              "IPY_MODEL_5006f73feaea45499b16559e8450f577"
            ]
          }
        },
        "d03ed22ae4384940a7d454af3716cc11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c33af93fbaaa488b9741f2b9393b4b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00c8ad795b32467fb352ed0721fee6a2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b81e178a772846358547ff6a4084c1f3"
          }
        },
        "5006f73feaea45499b16559e8450f577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f4be016d77f4461949712cbb0f36289",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [02:25&lt;00:00, 2.49B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f392c10e89b4b24a0ddab34a8e75e3f"
          }
        },
        "00c8ad795b32467fb352ed0721fee6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b81e178a772846358547ff6a4084c1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f4be016d77f4461949712cbb0f36289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f392c10e89b4b24a0ddab34a8e75e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11203ff22ce94cea85086bbf853d5ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cec29d2b8c2444b2b608b9103154d64e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bab451bbe14a4acf9d73a4730279e4b3",
              "IPY_MODEL_198270f4960442f2993b8583eba73de6"
            ]
          }
        },
        "cec29d2b8c2444b2b608b9103154d64e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bab451bbe14a4acf9d73a4730279e4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fd313e1954c4efaa1fe5b7e1dcda617",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 500709232,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 500709232,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71c3f493525d49c3962691a408027156"
          }
        },
        "198270f4960442f2993b8583eba73de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_938db702f98842bebeea000e33da405f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [02:24&lt;00:00, 3.46MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4caf8b9fd3b43168b6c4c577cb6d1b4"
          }
        },
        "7fd313e1954c4efaa1fe5b7e1dcda617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71c3f493525d49c3962691a408027156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "938db702f98842bebeea000e33da405f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4caf8b9fd3b43168b6c4c577cb6d1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/laser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znqBFEp7wtzP",
        "colab_type": "code",
        "outputId": "49994efe-f760-4136-9545-ccd83b6acc31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting laserembeddings\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/6b/93843d90080666571a79f8eb195fa58aa5e45cf24d36158b9c01dba306e2/laserembeddings-1.0.1-py3-none-any.whl\n",
            "Collecting transliterate==1.10.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/6e/9a9d597dbdd6d0172427c8cc07c35736471e631060df9e59eeb87687f817/transliterate-1.10.2-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (1.18.2)\n",
            "Collecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 14.1MB/s \n",
            "\u001b[?25hCollecting subword-nmt<0.4.0,>=0.3.6\n",
            "  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.6/dist-packages (from laserembeddings) (1.4.0)\n",
            "Requirement already satisfied: six>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from transliterate==1.10.2->laserembeddings) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->laserembeddings) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.38.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=33ac3f2656e9f8e85603c5f2d9a43976c34278b50d96db659ea1fcb8637aab0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: transliterate, sacremoses, subword-nmt, laserembeddings\n",
            "Successfully installed laserembeddings-1.0.1 sacremoses-0.0.35 subword-nmt-0.3.7 transliterate-1.10.2\n",
            "Downloading models into /usr/local/lib/python3.6/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzDKFfi4wWfz",
        "colab_type": "code",
        "outputId": "9b583b85-2d0b-4303-e37c-1b83c2f09d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from laserembeddings import Laser\n",
        "\n",
        "laser = Laser()\n",
        "#can this be any simpler? :)\n",
        "embeddings = laser.embed_sentences(['I love pasta.',\"J'adore les pâtes.\",'Ich liebe Pasta.'],lang=['en', 'fr', 'de'])\n",
        "\n",
        "print(embeddings)\n",
        "print(embeddings.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-5.2038918e-04 -2.8321847e-05 -1.6871424e-04 ...  3.4788882e-03\n",
            "  -1.9968925e-03  8.1148157e-03]\n",
            " [ 3.2193204e-03 -9.9815625e-05  5.9067814e-05 ...  7.6490371e-03\n",
            "   1.1962658e-03  2.4502571e-03]\n",
            " [ 5.3412537e-04 -3.6210149e-05 -1.4794602e-04 ...  6.1386405e-03\n",
            "  -1.6569842e-03  6.3126483e-03]]\n",
            "(3, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR2aTnaXyIRv",
        "colab_type": "text"
      },
      "source": [
        "# Test the embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC1ygwtO7H7W",
        "colab_type": "text"
      },
      "source": [
        "* We are working on a paraphrase corpus, from which I borrowed some early data\n",
        "* The two files below `yle.txt` and `hs.txt` contain some 200+ news titles from YLE and HS, judged by a human to be paraphrases or near-paraphrases of each other\n",
        "* The selection is such that lexical overlap is minimized\n",
        "* The two files are line-aligned\n",
        "* We could make a simple test of LASER, comparing them against each other to see if we can pair these up\n",
        "* In other words: for every HS title, find the nearest YLE title\n",
        "* Measure how often it is correct\n",
        "* Random baseline is roughly 1/200, i.e. about 0.5%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVSHlFY06osU",
        "colab_type": "code",
        "outputId": "10f12a21-32c3-44f3-9103-1fcd4446fa7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "!wget -nc http://dl.turkunlp.org/.ginter/hs.txt\n",
        "!wget -nc http://dl.turkunlp.org/.ginter/yle.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-23 10:05:45--  http://dl.turkunlp.org/.ginter/hs.txt\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24291 (24K) [text/plain]\n",
            "Saving to: ‘hs.txt’\n",
            "\n",
            "\rhs.txt                0%[                    ]       0  --.-KB/s               \rhs.txt              100%[===================>]  23.72K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-04-23 10:05:46 (250 KB/s) - ‘hs.txt’ saved [24291/24291]\n",
            "\n",
            "--2020-04-23 10:05:48--  http://dl.turkunlp.org/.ginter/yle.txt\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21392 (21K) [text/plain]\n",
            "Saving to: ‘yle.txt’\n",
            "\n",
            "yle.txt             100%[===================>]  20.89K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-04-23 10:05:48 (438 KB/s) - ‘yle.txt’ saved [21392/21392]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB0qsYL59l5R",
        "colab_type": "code",
        "outputId": "22a4fb9e-1d02-4019-bdeb-aaa85c2948e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def read_file(fname):\n",
        "  lines=[]\n",
        "  with open(fname) as f:\n",
        "    for line in f:\n",
        "      line=line.strip()\n",
        "      if not line:\n",
        "        continue\n",
        "      lines.append(line)\n",
        "  return lines\n",
        "\n",
        "hs=read_file(\"hs.txt\")\n",
        "yle=read_file(\"yle.txt\")\n",
        "\n",
        "hs_vectors=laser.embed_sentences(hs,\"fi\")\n",
        "yle_vectors=laser.embed_sentences(yle,\"fi\")\n",
        "\n",
        "print(\"hs\",hs_vectors.shape)\n",
        "print(\"yle\",yle_vectors.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hs (217, 1024)\n",
            "yle (217, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ47PYIO-PRS",
        "colab_type": "code",
        "outputId": "640132b4-dec1-44b9-fed7-7585c3c79180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import sklearn.metrics\n",
        "# Given two sets of vectors, this function calculates all-pair cosine distances\n",
        "all_dist=sklearn.metrics.pairwise_distances(hs_vectors,yle_vectors)\n",
        "print(\"Distance matrix shape:\", all_dist.shape)\n",
        "#we get a sentence-by-sentence matrix, with distances"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance matrix shape: (217, 217)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WOy2wU9-6XO",
        "colab_type": "code",
        "outputId": "57741e6f-266d-4094-af56-0dda97ef4e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "#Calculate for every row the document with minimal distance in that row (axis=-1 means minimum along the last axis)\n",
        "nearest=all_dist.argmin(axis=-1) #These are the nearest neighbors for each HS title (indices into YLE), perfect solution would be [0,1,2,3...,216]\n",
        "print(nearest)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[121   1   1   3 120 116   6   9   8   9 177  11 102  13  44  15 126  17\n",
            " 196 206 189  96  22  23  70   9  77 189 216  67  30 136  78  61  34  74\n",
            "  53  37 161  39  40 147 203  13  44  45   9  47  48  49  14  51 120  53\n",
            "  54  55 121  46  58 123  60  61 189  48  64  65  39  13 126  69  70  71\n",
            "  61  73  74  61  76  26 189  74  14  81  82  83  84  85  86  87 182  64\n",
            "  15 135 176 189  70  59 206  97 208  99  99  84 102 103 104 105  48  67\n",
            "  91 175 110  14 112 113  39 115 116 121 118  73 120 121 121 123 124 125\n",
            " 126 159 128 129 130  92 132 133 134  61 136 137 138   9  39 141 142 123\n",
            "  39   9  35  15 150 149  67 151 152 153 180 155 156 137 158  79 160 176\n",
            "  79 163 164 112  39 167 168 169 132 171 172 146  61 175 201 177 178 179\n",
            " 180  63 189 183 184  67  39 187 197 189  94 146 192 193 150 195 196 197\n",
            "  78  39 198  74 202 203 204 133 206   9 208 146  86  59  30 213 214 215\n",
            " 216]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvwQGUKY_akG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's package this all nicely into a function\n",
        "import random\n",
        "\n",
        "\n",
        "def eval_embeddings(texts1,texts2,vectors1,vectors2):\n",
        "  assert len(texts1)==len(texts2), \"We assume aligned data\"\n",
        "  all_dist=sklearn.metrics.pairwise_distances(vectors1,vectors2)\n",
        "  nearest=all_dist.argmin(axis=-1) #These are the nearest neighbors for each HS title (indices into YLE), perfect solution would be [0,1,2,3...,216]   \n",
        "  correct=[] #Let's put here the correct pairs\n",
        "  incorrect=[] #Let's put here the incorrect pairs\n",
        "  for i,txt1 in enumerate(texts1):\n",
        "    j=nearest[i] #the index at which the nearest sentence is\n",
        "    txt2=texts2[j] #..and its text\n",
        "    if i==j:\n",
        "      #This is correct\n",
        "      correct.append((txt1,txt2))\n",
        "    else:\n",
        "      incorrect.append((txt1,txt2))\n",
        "\n",
        "  print(f\"Correct {len(correct)}/{len(texts1)}={len(correct)/len(texts1)*100}%\") #these f-strings are really neat, you can embed expressions and have them printed\n",
        "  random.shuffle(correct)\n",
        "  random.shuffle(incorrect)\n",
        "  print(\"\\n\\n---------- Sample of correct ones:\")\n",
        "  for t1,t2 in correct[:15]:\n",
        "    print(t1)\n",
        "    print(t2)\n",
        "    print()\n",
        "  print(\"\\n\\n---------- Sample of incorrect ones:\\n\")\n",
        "  for t1,t2 in incorrect[:15]:\n",
        "    print(t1)\n",
        "    print(t2)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzFwrTZUCWMs",
        "colab_type": "code",
        "outputId": "d4f38db7-a4a2-44fb-fad5-825ccbdf7022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_embeddings(hs,yle,hs_vectors,yle_vectors)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct 110/217=50.69124423963134%\n",
            "\n",
            "\n",
            "---------- Sample of correct ones:\n",
            "Pankin työntekijän epäillään kavaltaneen satoja tuhansia euroja Länsi-Uudellamaalla\n",
            "Poliisi: Säästöpankin työntekijä myönsi 350 000 euron kavalluksen – siirtyy syyteharkintaan\n",
            "\n",
            "Poliisi takavarikoi koulun päättäjäis viikonloppuna vähemmän alkoholijuomia kuin viime vuonna – ”Lastensuojelu­ilmoitusten lukumäärän lasku näyttää jatkuvan”\n",
            "Nuoriso juhli koulujen päättymistä viime vuotta kuivemmin – myös poliisin haaviin jäi rutkasti vähemmän alaikäisten juhlajuomia\n",
            "\n",
            "Suomen teollisuus­tuotanto kasvoi vauhdikkaammin kuin lähes vuoteen\n",
            "Suomen teollisuus vahvassa vedossa huhtikuussa – tuotanto kasvoi laajalla rintamalla\n",
            "\n",
            "EU-virkamiehiä pyydetty välttämään Finnairin lentoja niiden kalleuden takia –  Miksi Brysselistä pääsee Tukholmaan 200 euroa halvemmalla kuin Helsinkiin?\n",
            "EU kehottaa virkamiehiään välttämään Finnairia budjettisyistä – Finnairin lennot voivat maksaa moninkertaisesti kilpailijoihin verrattuna\n",
            "\n",
            "Mies joutui raiskauksesta vankilaan väärän ilmiannon perusteella – uhri tunnusti seitsemän vuotta myöhemmin, nyt korkein oikeus purki tuomion\n",
            "Miehen raiskaustuomio purettiin, kun nainen vuosien jälkeen ilmoitti valehdelleensa\n",
            "\n",
            "Elinikään vaikuttavat geenit, ympäristötekijät ja sattuma – ”Jotkut hyötyvät elintapa­muutoksista enemmän ja jotkut vähemmän”, sanoo asiantuntija\n",
            "Hyvät geenit ja elintavat sekä turmilta säästyminen lisäävät elinvuosia\n",
            "\n",
            "Kansantaudit tappavat suomalaisia aiempaa harvemmin, mutta edessä siintää uusi uhka: lihavuus\n",
            "Suomalaisten riski kuolla ennenaikaisesti pienentynyt, lihominen hyvän kehityksen jarruna\n",
            "\n",
            "Poliisin kuulustelumateriaali: Helsingin keskustaan suunniteltua pommi-iskua valmisteli latvialainen rakennusmies, joka kannattaa kansallissosialismia\n",
            "Syyte: Mies valmisteli pommi-iskua Helsingin keskustaan, tarkoitus oli iskeä väkijoukkoon uudenvuodenaattona 2018\n",
            "\n",
            "Posti alentaa noin 700:n paketti- ja verkko­kauppa­työntekijän pohja­palkkaa: Pau ilmoitti aloittavansa lakot, työn­tekijöitä marssi ulos Tampereella ja Vantaalla\n",
            "Posti muuttaa noin 700 paketti- ja verkkokauppatyöntekijän työehtoja – pohjapalkka pienenee, tuottavuudesta palkitaan\n",
            "\n",
            "Poliisi tutkii murhaa Oulussa – neljän epäillään sekaantuneen henki­rikokseen, uhria ei ole löydetty\n",
            "Neljää epäillään osallisuudesta murhaan Oulussa – poliisi: rikos tapahtui soramontulla ja ruumis kätkettiin\n",
            "\n",
            "Venäjälle suuntautuva junaliikenne on pysähdyksissä, syynä sähköratavaurio\n",
            "Junaliikenne keskeytyi Luumäki–Vainikkala-välillä\n",
            "\n",
            "Trumpin yksityis­kerholla pidätettiin kiinalaisnainen, jolla oli kaksi passia, useita puhelimia ja muisti­tikussaan haittaohjelmia\n",
            "Kiinalainen nainen pidätettiin Trumpin klubilla Floridassa – sanoi osallistuvansa \"ystävyystapahtumaan\"\n",
            "\n",
            "Trump: Huawein tilanne voi ratketa osana Yhdysvaltojen ja Kiinan kauppaneuvotteluja\n",
            "Presidentti Trumpilla ja ulkoministeri Pompeolla eriävät kannat Huawein roolista USA:n ja Kiinan kauppakiistassa\n",
            "\n",
            "Öljyntorjunta Suomen aluevesillä päättyi, vuodon syyn tutkinta voi kestää viikkoja\n",
            "Öljynkeräys jatkuu Suomen Leijonan majakan alueella Turun saaristossa\n",
            "\n",
            "Perussuomalaisilla nuorilla kesäkuuhun asti aikaa selittää twiittiään: Valtionapu saatetaan periä takaisin\n",
            "PS-Nuorten valtionapu vaakalaudalla, ministeriö perää järjestöltä selvitystä\n",
            "\n",
            "\n",
            "\n",
            "---------- Sample of incorrect ones:\n",
            "\n",
            "Lämpöennätyksiä rikkoutui jälleen Australiassa, lämpötila nousi jopa 49,8 asteeseen\n",
            "Kaksi kaaharia hurjasteli Tuusulanväylällä rajua ylinopeutta – poliisin edellä yli 180 km/h\n",
            "\n",
            "Vienti­alojen lakot alkoivat: Mukana jopa 100 000 työntekijää, taloudelliset menetykset nousevat arviolta 400 miljoonaan\n",
            "Posti muuttaa noin 700 paketti- ja verkkokauppatyöntekijän työehtoja – pohjapalkka pienenee, tuottavuudesta palkitaan\n",
            "\n",
            "HS Järvenpää: Miestä ammuttiin kerrostalon pihalla Järvenpäässä syksyllä, uhri poistui paikalta verta vuotaen – Poliisi: Rikos oli suunniteltu etukäteen\n",
            "Neljää epäillään osallisuudesta murhaan Oulussa – poliisi: rikos tapahtui soramontulla ja ruumis kätkettiin\n",
            "\n",
            "Pahoinpitelystä tuomittu poliisi erotettiin määräajaksi – video näyttää väkivallanteon poliisiasemalla\n",
            "Poliisi tutkii vakavaa henkeen ja terveyteen kohdistunutta rikosta Pertunmaan Kuortissa – pyysi Puolustusvoimilta virka-apua\n",
            "\n",
            "Poliisi paljasti ison kokaiinibisneksen Pirkanmaalla – ryhmän epäilleen levittäneen jopa 5 000 käyttöannosta\n",
            "Tutkijat loivat sarvikuonoalkioita – Koeputkihedelmöitys tuo toivoa lajille, jota jäljellä vain kaksi naarasta\n",
            "\n",
            "Kuopion kouluhyökkääjää vaaditaan vangittavaksi epäiltynä murhasta ja yhdeksästä murhan yrityksestä\n",
            "Järvenpään syyskuista ampumista tutkitaan murhan yrityksenä ja ampuma-aserikoksena\n",
            "\n",
            "Veroprosenttia nostavien kuntien määrä voi ensi vuonna lähes kaksinkertaistua\n",
            "Aseluvan verkkohaku lykkääntyy jo toistamiseen\n",
            "\n",
            "Miesjoukon epäillään keplotelleen itselleen arvokkaan kultaerän Helsingissä: ”Tapahtui jonkinlainen silmänkääntötemppu”\n",
            "Helsingissä Sörnäisten puukotuksesta epäilty henkilö saatu kiinni\n",
            "\n",
            "Yhdysvaltalaistuomari tukee demokraattien tietopyyntöä Trumpin aiemmista liiketoimista\n",
            "USA:n puolustusvoimat julkaisi videon Isis-johtajan kuolemaan johtaneesta operaatiosta\n",
            "\n",
            "Sote-uudistuksen aikataulut natisevat – lakien yksityis­kohdat valkenevat kansan­edustajille pikku hiljaa\n",
            "Vuorossa salkkujako – puolueiden puheenjohtajat koolle ratkomaan ministeripaikkoja\n",
            "\n",
            "Naisen astma puhkeaa usein vasta aikuisena, tutkijan mukaan merkittävin riski­tekijä on suku­tausta\n",
            "Tutkijat loivat sarvikuonoalkioita – Koeputkihedelmöitys tuo toivoa lajille, jota jäljellä vain kaksi naarasta\n",
            "\n",
            "Potilashuoneen sähkölaitteet syttyivät palamaan Tampereen yliopistollisessa sairaalassa\n",
            "Aseistautuneet hyökkääjät iskivät ministeriörakennukseen Kabulissa\n",
            "\n",
            "Ylitorniolla ammuttiin junan matkustaja­vaunua haulikolla, poliisi kaipaa lisätietoja\n",
            "Miehen epäillään kähmineen ja lyöneen lasta Turun Puutorilla – poliisi pyytää havaintoja\n",
            "\n",
            "Perheenisä Kim Holvialan sivustolla liikkui vuosia huumeita – Hovi­oikeus linjaa, mikä Holvialan vastuu huume­kaupasta oli\n",
            "Vuosituhannen vaihteen asfalttikartellista uusi päätös – KKO pani kartelliyritysten liiketoiminnan ostaneet firmat vastuuseen\n",
            "\n",
            "Kokaiinista on tullut entistä isompi osa alamaailman huumebisnestä – Se näkyy myös Suomessa, sanoo Europolin Suomen-edustaja\n",
            "Öljynkeräys jatkuu Suomen Leijonan majakan alueella Turun saaristossa\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRvwS7HqT8-9",
        "colab_type": "text"
      },
      "source": [
        "# Try with BERT?\n",
        "\n",
        "*   We could try with BERT\n",
        "*   Test the [CLS] token as the sentence embedding\n",
        "*   Test the average of token embeddings as the sentence embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLEW-5WMCfjQ",
        "colab_type": "code",
        "outputId": "9463ea91-543c-44ef-9626-8ea2602a4c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "142dd5933d9c4499a538fa8a579a0338",
            "d03ed22ae4384940a7d454af3716cc11",
            "c33af93fbaaa488b9741f2b9393b4b16",
            "5006f73feaea45499b16559e8450f577",
            "00c8ad795b32467fb352ed0721fee6a2",
            "b81e178a772846358547ff6a4084c1f3",
            "8f4be016d77f4461949712cbb0f36289",
            "3f392c10e89b4b24a0ddab34a8e75e3f",
            "11203ff22ce94cea85086bbf853d5ede",
            "cec29d2b8c2444b2b608b9103154d64e",
            "bab451bbe14a4acf9d73a4730279e4b3",
            "198270f4960442f2993b8583eba73de6",
            "7fd313e1954c4efaa1fe5b7e1dcda617",
            "71c3f493525d49c3962691a408027156",
            "938db702f98842bebeea000e33da405f",
            "f4caf8b9fd3b43168b6c4c577cb6d1b4"
          ]
        }
      },
      "source": [
        "#Note: since LASER is torch, maybe we continue in torch for the fun of it? :) (and you also asked for some torch examples)\n",
        "!pip install transformers\n",
        "import transformers\n",
        "\n",
        "bert_model = transformers.BertModel.from_pretrained(\"bert-base-finnish-cased-v1\") #models can be loaded by name from this list: https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L35\n",
        "bert_model = bert_model.cuda() #move the model to GPU\n",
        "bert_model.eval() #tell the model it will be used for predictions, not training (disables dropout for example)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 30.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 26.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 31.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 37.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 41.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 43.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 46.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 47.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 47.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 48.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 29.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 29.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 29.1MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 29.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 29.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n",
            "Installing collected packages: sentencepiece, tokenizers, transformers\n",
            "Successfully installed sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "142dd5933d9c4499a538fa8a579a0338",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=362, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11203ff22ce94cea85086bbf853d5ede",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=500709232, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(50105, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_12ElwHjDcks",
        "colab_type": "code",
        "outputId": "cda49081-7207-460b-bc60-219a0b9f8495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "#Load the Finnish BERT tokenizer\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-finnish-cased-v1\") #also tokenizers can be loaded by nae\n",
        "\n",
        "def tokenize_texts(texts):\n",
        "  tokenized_ids=[tokenizer.encode(txt,add_special_tokens=True) for txt in texts] #this runs the BERT tokenizer, returns list of lists of integers\n",
        "  tokenized_ids_t=[torch.tensor(ids,dtype=torch.long) for ids in tokenized_ids] #turn lists of integers into torch tensors\n",
        "  tokenized_single_batch=torch.nn.utils.rnn.pad_sequence(tokenized_ids_t,batch_first=True) #zero-padding\n",
        "  return tokenized_single_batch\n",
        "\n",
        "hs_data=tokenize_texts(hs).cuda() #tokenize and move to GPU\n",
        "yle_data=tokenize_texts(yle).cuda()\n",
        "\n",
        "print(hs_data.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([217, 37])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QitzfbyLyoXY",
        "colab_type": "text"
      },
      "source": [
        "**WARNING** ... I now added the attention mask to BERT which I accidentally missed during the lecture, and the results of BERT went way up, so the conclusions I made during the lecture do not match what one sees here. Sorry about that, these things happen when in hurry. :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJdcSQNcI_It",
        "colab_type": "code",
        "outputId": "05893c3b-851e-4bcd-be2f-99088908e3d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#This is how you run BERT in torch\n",
        "data=hs_data\n",
        "with torch.no_grad(): #tell the model not to gather gradients since we are evaluating, not training, saves memory and troubles\n",
        "  mask=data.clone().float() # this is a mask telling which tokens are padding and which are real\n",
        "  mask[data>0]=1.0 #We need to set this to 1 for tokens that the attention should see, and 0 for those that are mere padding\n",
        "\n",
        "  emb=bert_model(data.cuda(),attention_mask=mask) #applies the model and returns several things, we care about the first. Documentation: https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L648\n",
        "  print(emb[0].shape)  # word x sequence x embedding\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([217, 37, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnxKXs1OOFRL",
        "colab_type": "code",
        "outputId": "454a010c-f510-4c5a-803d-0ef6993cceef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Let's pack this into a nice function\n",
        "def embed(data,how_to_pool=\"CLS\"):\n",
        "  with torch.no_grad(): #tell the model not to gather gradients\n",
        "    mask=data.clone().float() #\n",
        "    mask[data>0]=1.0\n",
        "    emb=bert_model(data.cuda(),attention_mask=mask.cuda()) #runs BERT and returns several things, we care about the first\n",
        "    #emb[0]  # batch x word x embedding\n",
        "    if how_to_pool==\"AVG\":\n",
        "      pooled=emb[0]*(mask.unsqueeze(-1)) #multiply everything by the mask\n",
        "      pooled=pooled.sum(1)/mask.sum(-1).unsqueeze(-1) #sum and divide by non-zero elements in mask to get masked average\n",
        "    elif how_to_pool==\"CLS\":\n",
        "      pooled=emb[0][:,0,:].squeeze() #Pick the first token as the embedding\n",
        "    else:\n",
        "      assert False, \"how_to_pool should be CLS or AVG\"\n",
        "    print(\"Pooled shape:\",pooled.shape)\n",
        "  return pooled.cpu().numpy() #done! move data back to CPU and extract the numpy array\n",
        "\n",
        "hs_emb_cls=embed(hs_data,\"CLS\")\n",
        "yle_emb_cls=embed(yle_data,\"CLS\")\n",
        "\n",
        "hs_emb_avg=embed(hs_data,\"AVG\")\n",
        "yle_emb_avg=embed(yle_data,\"AVG\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pooled shape: torch.Size([217, 768])\n",
            "Pooled shape: torch.Size([217, 768])\n",
            "Pooled shape: torch.Size([217, 768])\n",
            "Pooled shape: torch.Size([217, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmEMNsMIV2vt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IVtrzrp_Nh4",
        "colab_type": "code",
        "outputId": "63d9b54c-7546-4d16-c5a4-63e83997d266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_embeddings(hs,yle,hs_emb_avg,yle_emb_avg)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct 155/217=71.42857142857143%\n",
            "\n",
            "\n",
            "---------- Sample of correct ones:\n",
            "Pääministeri Sipilä Oulun epäillystä seksuaali­rikoksesta: ”Oikeusvaltiossa syylliset saavat rangaistuksen etnisyydestä riippumatta”\n",
            "Pääministeri Sipilä Oulun raiskausepäilyistä: \"Epäinhimillinen teko, jonka pahuutta ei voi käsittää\"\n",
            "\n",
            "Työleirille karkotetuksi huhuttu Pohjois-Korean neuvottelija palasi parrasvaloihin\n",
            "Kim Jong-unin luottomies ei joutunutkaan pakkotyöhön Trump-huippukokouksen epäonnistumisen takia – nähty konsertissa johtajan rinnalla\n",
            "\n",
            "Kokoomus esittelee sittenkin sotemallin ennen vaaleja, mutta aikataulusta ei ole vielä tietoa\n",
            "Ryhmäjohtaja Jokinen korjaa sanomisiaan: Kokoomus esittelee sote-mallinsa, aikataulu vielä auki\n",
            "\n",
            "Asvalttihuijaria epäillään törkeästä veropetoksesta – yhtiö myynyt omakotitaloasukkaille pihatöitä Etelä-Suomessa\n",
            "Asvaltti- ja pihaurakoita tehnyt yhtiö jätti verot maksamatta –  irlantilainen osakas etsintäkuulutettu\n",
            "\n",
            "Brexit-neuvottelut konservatiivien ja työväen­puolueen välillä katkesivat, Mayn lähtölaskenta alkoi\n",
            "Britannian pääministeri May väistymässä kesäkuun brexit-äänestyksen jälkeen\n",
            "\n",
            "Useilla pankeilla oli sunnuntaina vakavia yhteysongelmia – palvelut palautuivat käyttöön alkuillasta\n",
            "Usealla pankilla laaja ongelma verkkopankin ja pankkikorttien kanssa – vian kestosta ei ole tietoa\n",
            "\n",
            "Patrik Leppänen, 22, ei totellut työnantajan käskyä ottaa Roosa nauha pois rinta­pielestään lento­aseman turva­tarkastuksessa ja sai potkut – ”Halusin osoittaa tukea äidilleni”\n",
            "Irtisanottu turvatarkastaja puolustaa tekoaan läheisensä  rintasyövällä, \"ei kaduta yhtään\" – Airpro: työntekijää varoitettu useasti\n",
            "\n",
            "Mansikkahuijauksia aletaan suitsia kemian keinoin: Isotooppi­analyysi paljastaa marjan alkuperän\n",
            "Uusi menetelmä ehkäisee ulkomaisten mansikoiden myyntiä suomalaisina\n",
            "\n",
            "Yli puolet suomalaisista vastustaa Nato-jäsenyyttä, kertoo tuore kysely\n",
            "Reilu puolet suomalaisista vastustaa Natoon liittymistä\n",
            "\n",
            "Ylitorniolla ammuttiin junan matkustaja­vaunua haulikolla, poliisi kaipaa lisätietoja\n",
            "Poliisi pyytää havaintoja Ylitornion juna-ampumisesta – laukaukset mahdollisesti metsästysaseesta\n",
            "\n",
            "Poliisi kaipaa edelleen vihjeitä Somerolla kadonneeseen naiseen liittyen, julkaisi kartan epäillyistä henkirikos­paikoista\n",
            "Poliisi kaipaa lisää havaintoja somerolaisnaisen murhasta epäillyn miehen liikkeistä – uhri edelleen kateissa\n",
            "\n",
            "Clintonin sähkö­posti­tutkinnalle päätös: ei tahallista varomattomuutta\n",
            "Clintonin sähköposteihin liittyvä tutkinta saatiin päätökseen – varomattomuus ei ollut tarkoituksellista\n",
            "\n",
            "Mediayhtiö Sanoma lähtee mukaan tapahtumabisnekseen – ostaa N.C.D. Productionilta festari-, konsertti- ja risteilyliiketoiminnan\n",
            "Sanoma rynnistää mukaan festaribisnekseen – osti muun muassa RMJ:n, Tammerfestin ja Suomipop-festivaalit\n",
            "\n",
            "Putinin tiedottajan tyttären harjoittelu Euroopan parlamentissa herättää epäilyjä ranskalaisen euro­edustajan lojaaliudesta, sanoo Liisa Jaakonsaari\n",
            "Putinin tiedottajan tytär on harjoittelussa Euroopan parlamentissa –  salaiset tiedot käytettävissä?\n",
            "\n",
            "Tulli epäilee: Suomalaiskaksikko salakuljetti myyntiin yli 2 000 kiloa nuuskaa\n",
            "Pääkaupunkiseudulle tuotiin yli kaksi tuhatta kiloa nuuskaa – kaupattiin sosiaalisessa mediassa\n",
            "\n",
            "\n",
            "\n",
            "---------- Sample of incorrect ones:\n",
            "\n",
            "Sote-uudistuksen aikataulut natisevat – lakien yksityis­kohdat valkenevat kansan­edustajille pikku hiljaa\n",
            "Ryhmäjohtaja Jokinen korjaa sanomisiaan: Kokoomus esittelee sote-mallinsa, aikataulu vielä auki\n",
            "\n",
            "Nordea sai uuden konserni­johtajan, kurssi nousussa – Suuromistaja Gardell vaatii kannattavuuden parantamista nopeasti ja ”dramaattisesti”\n",
            "Metsäjätti UPM paisuu – tuotteiden hintoja saatu hilattua ylöspäin ja odotukset korkealla erinomaisesta vuodesta\n",
            "\n",
            "Yli 500 ihmisen sairauskertomukset lähetettiin vääriin osoitteisiin Helsingin seudulla – Hus pohtii toimia postitusfirmaa vastaan: ”Enää ei saa tapahtua näin”\n",
            "Viranomaissivustot toimivat taas, iltapäivän palvelunestohyökkäys ohi – \"Palvelunestohyökkääjä löytänyt aivan uudenlaisen tavan päästä läpi\"\n",
            "\n",
            "Sanoma ostaa hollantilaisen opetusalan yhtiön 277 miljoonalla\n",
            "Uusi päivä -sarjaa tuottanut Studio Mediapolis lopettaa toimintansa – kuuden viikon yt-neuvottelut päättyivät\n",
            "\n",
            "Kyberturvallisuuskeskus varoittaa uudenlaisista huijaus­puheluista, jotka näyttävät erehdyttävästi tulevan suomalaisesta numerosta\n",
            "Viranomaissivustot toimivat taas, iltapäivän palvelunestohyökkäys ohi – \"Palvelunestohyökkääjä löytänyt aivan uudenlaisen tavan päästä läpi\"\n",
            "\n",
            "HS Järvenpää: Miestä ammuttiin kerrostalon pihalla Järvenpäässä syksyllä, uhri poistui paikalta verta vuotaen – Poliisi: Rikos oli suunniteltu etukäteen\n",
            "Neljää epäillään osallisuudesta murhaan Oulussa – poliisi: rikos tapahtui soramontulla ja ruumis kätkettiin\n",
            "\n",
            "Yhdysvaltalaistuomari tukee demokraattien tietopyyntöä Trumpin aiemmista liiketoimista\n",
            "Yhdysvaltalainen tuomioistuin: Trumpin Twitter-blokkaukset ovat perustuslain vastaista toimintaa\n",
            "\n",
            "Palvelunesto­hyökkäys on kaatanut esimerkiksi poliisin ja Verohallinnon verkko­sivut\n",
            "Viranomaissivustot toimivat taas, iltapäivän palvelunestohyökkäys ohi – \"Palvelunestohyökkääjä löytänyt aivan uudenlaisen tavan päästä läpi\"\n",
            "\n",
            "Hallituksen lakiesitys voisi lisätä apteekkien määrää, mutta ei vapauttaisi niitä kilpailulle – ”Mahdollista että jää ihan kuolleeksi kirjaimeksi”\n",
            "Professori Hiilamo sote-kuulemisesta: Lisää siirtymäaikoja tarvitaan – \"Tuntui olevan aika laaja yhteisymmärrys, että ne olisivat ihan tarpeellisia\"\n",
            "\n",
            "Selvitys: Toimittaja joutuu nettihäirinnän kohteeksi, jos hän kirjoittaa tietyistä aiheista – tai jos hän on joutunut äärioikeiston silmätikuksi\n",
            "9 puolueelta yhteinen kannanotto: Vaalihäirintä uhkaa demokratiaa – tärkeää, että äänestäjät tunnistavat valeuutisoinnin\n",
            "\n",
            "Ulkomaalaiset turistit moottorikelkka­turmissa Lapissa, ajoivat päin hiihtäjää ja puuta, yksi kaatui sillalla – kaksi loukkaantui vakavasti\n",
            "Hurja takaa-ajo Helsingissä – lapsi työnnettiin kumoon kassajonossa, jalankulkijat hyppivät sivuun poliisia paenneen auton tieltä\n",
            "\n",
            "Lennonjohtajilta varoitus lakoista tammi­kuun alussa – syynä pettymys tes-neuvotteluihin\n",
            "Vientialojen laajat lakot alkavat maanantaina – neuvotteluissa ei edistytty\n",
            "\n",
            "Perussuomalaisilla nuorilla kesäkuuhun asti aikaa selittää twiittiään: Valtionapu saatetaan periä takaisin\n",
            "9 puolueelta yhteinen kannanotto: Vaalihäirintä uhkaa demokratiaa – tärkeää, että äänestäjät tunnistavat valeuutisoinnin\n",
            "\n",
            "Eduskunnassa suullinen kysely­tunti, sen jälkeen keskustellaan pysyvää kesäaikaa ehdottavasta kansalais­aloitteesta – suora lähetys juuri nyt\n",
            "9 puolueelta yhteinen kannanotto: Vaalihäirintä uhkaa demokratiaa – tärkeää, että äänestäjät tunnistavat valeuutisoinnin\n",
            "\n",
            "Vaa'ankieliasemassa oleva republikaani vastustaa todistajien kutsumista Trumpin oikeudenkäyntiin – Senaatti äänestää asiasta tänään\n",
            "Yhdysvaltalainen tuomioistuin: Trumpin Twitter-blokkaukset ovat perustuslain vastaista toimintaa\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OESxU6_V6ge",
        "colab_type": "code",
        "outputId": "dac0095c-04cd-4eb5-9d2b-9f6b878344ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_embeddings(hs,yle,hs_emb_cls,yle_emb_cls)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct 152/217=70.04608294930875%\n",
            "\n",
            "\n",
            "---------- Sample of correct ones:\n",
            "Kolumbialainen pormestari vaatii anteeksipyyntöä salsatähdiltä – syynä säkeiden viittaus huumeparoni Escobariin\n",
            "Medellínin kokaiini ja Rihannan rakkaussuhde olivat liikaa – Muusikkoparia vaaditaan pyytämään hittiään anteeksi naisilta ja Medellínin kaupungilta\n",
            "\n",
            "Oodissa yli 3,1 miljoonaa kävijää viime vuonna – ”Ylitti kaikki odotukset”\n",
            "Oodi veti Helsingin kirjastot ennätyslukemiin\n",
            "\n",
            "TV2:n Uusi päivä -sarjan lopettaminen vie työn monelta näyttelijältä\n",
            "Yt-neuvottelut alkoivat Mediapoliksessa – Uusi päivä -tv-sarja päättyy vuoden lopussa\n",
            "\n",
            "Suojelupoliisi osallistuu Airiston Helmen kotietsintä­aineiston tarkasteluun – valtava aineisto vastaa jopa 100 000 muisti­tikun sisältöä\n",
            "Poliisilla iso urakka edessä: Supo auttaa KRP:tä Turun saaristosta löytyneen materiaalin läpikäymisessä\n",
            "\n",
            "Supon ex-työntekijä uhkasi poliisin mukaan kansallista turvallisuutta – oikeus ottaa kantaa, olivatko miehen tietohaut vaarallisia\n",
            "Käräjäoikeus alkaa käsitellä suojelupoliisin ex-työntekijän syytettä turvallisuussalaisuuden paljastamisesta – epäillään haalineen järjestelmistä tietoja muun muassa vastatiedustelusta\n",
            "\n",
            "Poliisin kuulustelumateriaali: Helsingin keskustaan suunniteltua pommi-iskua valmisteli latvialainen rakennusmies, joka kannattaa kansallissosialismia\n",
            "Syyte: Mies valmisteli pommi-iskua Helsingin keskustaan, tarkoitus oli iskeä väkijoukkoon uudenvuodenaattona 2018\n",
            "\n",
            "Syyrian epäillyn kaasuiskun tutkijat ryhtyvät poikkeuksellisiin toimiin: tutkivat haudattuja ruumiita\n",
            "Kemiallisten aseiden tutkijat aikovat nostaa Duman uhreja haudoista näytteitä varten\n",
            "\n",
            "Kanadan syrjä­seutujen murhista epäiltyjen kuolin­syyn uskotaan olevan itse­murha\n",
            "Kanadassa viime viikolla löytyneet ruumiit varmistuivat murhista epäillyksi teinikaksikoksi\n",
            "\n",
            "Eduskuntapuolueilta yhteinen vetoomus kansalaisille: Olkaa tarkkana vale­uutisten suhteen\n",
            "9 puolueelta yhteinen kannanotto: Vaalihäirintä uhkaa demokratiaa – tärkeää, että äänestäjät tunnistavat valeuutisoinnin\n",
            "\n",
            "Finnwatch arvostelee Danske Bankia: Pankki tiesi Viron konttorin rahanpesusta vuosia eikä maininnut niistä mitään vuosiraporteissaan\n",
            "Finnwatch: Pankeille sapiskaa puutteellisesta veroraportoinnista, ei viitteitä aggressiivisesta verosuunnittelusta\n",
            "\n",
            "Kysely: Lähes puolet nuorista työntekijöistä ei saa pitää neljän viikon yhtäjaksoista lomaa\n",
            "Puolet nuorista työntekijöistä ei saa pitää kesälomaa putkeen, vaikka haluaisi – \"Yhdenjaksoisen loman puute on yleensä aina lainvastainen\"\n",
            "\n",
            "Muuttovalmiit valmistalot ohittivat suosiossa perinteiset talopaketit\n",
            "Suomalaiset haluavat omakotitalonsa yhä valmiimpina – avaimet vaan käteen ja muuttamaan\n",
            "\n",
            "Yli puolet suomalaisista vastustaa Nato-jäsenyyttä, kertoo tuore kysely\n",
            "Reilu puolet suomalaisista vastustaa Natoon liittymistä\n",
            "\n",
            "Hyvä tulos UPM:ltä: Liikevoitto kasvoi tuntuvasti ja yhtiö ennakoi vielä parempaa kehitystä loppuvuonna\n",
            "Metsäjätti UPM paisuu – tuotteiden hintoja saatu hilattua ylöspäin ja odotukset korkealla erinomaisesta vuodesta\n",
            "\n",
            "Lännen Media: Lähes kaksi kolmasosaa suomalaisista tyytyväisiä Marinin hallitukseen\n",
            "LM: Tyytyväisyys Marinin hallitukseen kasvanut pääministerin vaihdon jälkeen\n",
            "\n",
            "\n",
            "\n",
            "---------- Sample of incorrect ones:\n",
            "\n",
            "Päiväkoti tuhoutui tulipalossa purkukuntoon Tampereella, naapurin 12-kerroksinen kerrostalo evakuoitiin ja kärsi savuvahinkoja\n",
            "Taysissa tulipalo – potilaita evakuoitu, vapaapäivää sairaalan lähellä viettänyt paloesimies sammutti palon\n",
            "\n",
            "Poliisi saanut useita kymmeniä uusia vihjeitä liittyen lasten törkeistä hyväksikäytöistä epäiltyyn ”Enoon”: Joukossa mahdollisia uhreja\n",
            "Poliisille tullut useita kymmeniä yhteydenottoja \"Enosta\" – mahdollisesti kaksi uutta uhria\n",
            "\n",
            "Aselupaa ei vielä voikaan hakea nettihakemuksella\n",
            "Työtön voi nyt olla hyväksyttävästi aktiivinen ilman työviranomaisten palveluita – Kela vaatii todistuksen\n",
            "\n",
            "Kysely: Valtaosa suomalaisista ei halua suurta perintöä vanhemmiltaan\n",
            "Reilu puolet suomalaisista vastustaa Natoon liittymistä\n",
            "\n",
            "Kuortissa paljastunutta henki­rikosta tutkitaan murhana, neljä epäiltyä otettu kiinni – tapaus aiheutti ison operaation ABC-asemalla\n",
            "KRP tutkii epäiltyä henkirikosta Somerolla – nuori varusmiesnainen nähtiin viimeksi kotipihallaan kesäkuussa\n",
            "\n",
            "Isis ilmoitti olevansa Kabulin terrori-iskun takana\n",
            "USA:n puolustusvoimat julkaisi videon Isis-johtajan kuolemaan johtaneesta operaatiosta\n",
            "\n",
            "Lisätietoa Lahden poliisioperaatiosta: epäilty antautui poliisille itse, hallussa olleella aseella ei uhkailtu ketään\n",
            "Uutta tietoa Tampereen koulupuukotuksesta: Taustalla riita, uhri ja epäilty alle 15-vuotiaita – \"Ei tapahtunut ihan hetken mielijohteesta\"\n",
            "\n",
            "Opiskelijoille löytyi selvityksessä ihanneansio – Tuhannen euron yläpuolella tilanne muuttuu ja pänttäämisestä tulee kannattavampaa\n",
            "Posti muuttaa noin 700 paketti- ja verkkokauppatyöntekijän työehtoja – pohjapalkka pienenee, tuottavuudesta palkitaan\n",
            "\n",
            "Posti alentaa noin 700:n paketti- ja verkko­kauppa­työntekijän pohja­palkkaa: Pau ilmoitti aloittavansa lakot, työn­tekijöitä marssi ulos Tampereella ja Vantaalla\n",
            "AKT laajentaa tukitoimiaan Postin työkiistassa lisää ja lisää – ylityö- ja vuoronvaihtokielto tuleekin koskemaan lähes kaikkia liiton työntekijöitä\n",
            "\n",
            "HS Järvenpää: Miestä ammuttiin kerrostalon pihalla Järvenpäässä syksyllä, uhri poistui paikalta verta vuotaen – Poliisi: Rikos oli suunniteltu etukäteen\n",
            "Uutta tietoa Tampereen koulupuukotuksesta: Taustalla riita, uhri ja epäilty alle 15-vuotiaita – \"Ei tapahtunut ihan hetken mielijohteesta\"\n",
            "\n",
            "Ulkomaalaiset turistit moottorikelkka­turmissa Lapissa, ajoivat päin hiihtäjää ja puuta, yksi kaatui sillalla – kaksi loukkaantui vakavasti\n",
            "Hurja takaa-ajo Helsingissä – lapsi työnnettiin kumoon kassajonossa, jalankulkijat hyppivät sivuun poliisia paenneen auton tieltä\n",
            "\n",
            "Keskon autoliikkeiden yt-neuvottelut päättyivät: työpaikkansa menettää 100 henkeä\n",
            "Yt-neuvottelut alkoivat Mediapoliksessa – Uusi päivä -tv-sarja päättyy vuoden lopussa\n",
            "\n",
            "Kuopion kouluhyökkääjää vaaditaan vangittavaksi epäiltynä murhasta ja yhdeksästä murhan yrityksestä\n",
            "Järvenpään syyskuista ampumista tutkitaan murhan yrityksenä ja ampuma-aserikoksena\n",
            "\n",
            "Toisen rikoksen yhteydessä löytynyt dna johdatti poliisin epäillyn seksuaalirikollisen jäljille, tutkinnassa kesällä 2018 Espoossa tapahtunut törkeä raiskaus\n",
            "Poliisi epäilee \"Enoksi\" kutsuttua miestä useista lapseen kohdistuneista seksuaalirikoksista Helsingissä – ainakin 12 uhria\n",
            "\n",
            "Toinen Kampissa puukotetuista miehistä menehtyi vammoihinsa\n",
            "Yksi ihminen kuoli yksityisasunnossa Sipoossa sunnuntaina – Poliisi tutkii tapausta tappona\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le84A4hyV7bx",
        "colab_type": "text"
      },
      "source": [
        "# What have we learned?\n",
        "\n",
        "**WARNING:** the conclusions changed when the mask was fixed\n",
        "\n",
        "* BERT embeddings are better than LASER\n",
        "* Average is marginally better than CLS\n",
        "* What kind of intuitive insight one gets when looking at the correct and incorrect predictions? What does the model base its decisions on?\n",
        "\n"
      ]
    }
  ]
}