{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-sequence RNN\n",
    "\n",
    "This notebook shows an example of a character-level sequence-to-sequence recurrent neural network model using Keras.\n",
    "\n",
    "The implementation and example data draw on [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) and [English to Katakana using a Sequence-to-Sequence model](https://github.com/wanasit/katakana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The following variables configure a few aspects of the data, model, and training process. To adapt this example to a different dataset, you'll probably want to change these to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of examples to read\n",
    "MAX_EXAMPLES = 100000\n",
    "\n",
    "# Maximum length of input sequence in characters\n",
    "INPUT_LENGTH = 20\n",
    "\n",
    "# Maximum length of output sequence in characters\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "# Number of epochs to train for\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Size of character embeddings\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Size of RNN states\n",
    "RNN_UNITS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "We'll be using the English to Japanese katakana characters dataset from [English to Katakana using a Sequence-to-Sequence model](https://github.com/wanasit/katakana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data.csv’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/wanasit/katakana/master/dataset/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paranthropus → パラントロプス\n",
      "Jarret Martin → ジャレット・マーティン\n",
      "Ildefons Lima → イルデフォンス・リマ・ソラ\n",
      "Joseph Calleia → ジョセフ・カレイア\n",
      "Rorschach → ロールシャッハ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def load_data(fn, separator=',', has_header_line=True, max_examples=None):\n",
    "    data = []\n",
    "    with open(fn) as f:\n",
    "        if has_header_line:\n",
    "            next(f)    # skip header\n",
    "        for line in f:\n",
    "            if max_examples is not None and len(data) >= max_examples:\n",
    "                break\n",
    "            line = line.rstrip('\\n')\n",
    "            input_text, output_text = line.split(separator)\n",
    "            data.append([input_text, output_text])\n",
    "    return data\n",
    "\n",
    "\n",
    "data = load_data('data.csv', max_examples=MAX_EXAMPLES)\n",
    "\n",
    "random.seed(1234)    # make random.shuffle() repeatable\n",
    "random.shuffle(data)\n",
    "\n",
    "input_texts = [input_text for input_text, output_text in data]\n",
    "output_texts = [output_text for input_text, output_text in data]\n",
    "\n",
    "\n",
    "# Have a look at the source data\n",
    "for i in range(5):\n",
    "    print(input_texts[i], '→', output_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize on the character level with lowercasing. To allow different input and output alphabets, create separate tokenizers for each.\n",
    "\n",
    "We're slightly abusing the tokenizer's out-of-vocabulary item support here to introduce a special `<START>` token into the mapping. As we're not restricting the number of words, this token will never be output by the tokenizer, so we're free to use it for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "input_tokenizer = Tokenizer(lower=True, char_level=True)\n",
    "output_tokenizer = Tokenizer(lower=True, char_level=True, oov_token='<START>')\n",
    "\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "output_tokenizer.fit_on_texts(output_texts)\n",
    "\n",
    "# Remember these\n",
    "INPUT_VOCAB_SIZE = max(input_tokenizer.word_index.values()) + 1\n",
    "OUTPUT_VOCAB_SIZE = max(output_tokenizer.word_index.values()) + 1\n",
    "START_INDEX = output_tokenizer.word_index['<START>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at those mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in input mapping: 134\n",
      "{' ': 7,\n",
      " 'a': 1,\n",
      " 'e': 2,\n",
      " 'i': 5,\n",
      " 'l': 8,\n",
      " 'n': 4,\n",
      " 'o': 6,\n",
      " 'r': 3,\n",
      " 's': 9,\n",
      " 't': 10}\n",
      "Number of entries in output mapping: 88\n",
      "{'<START>': 1,\n",
      " 'ア': 8,\n",
      " 'ス': 6,\n",
      " 'ト': 10,\n",
      " 'ラ': 9,\n",
      " 'リ': 7,\n",
      " 'ル': 5,\n",
      " 'ン': 4,\n",
      " '・': 3,\n",
      " 'ー': 2}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint    # pretty-printer\n",
    "\n",
    "\n",
    "def truncate_dict(d, count=10):\n",
    "    # Returns at most count items from the given dictionary.  \n",
    "    return dict(i for i, _ in zip(d.items(), range(count)))\n",
    "\n",
    "\n",
    "print('Number of entries in input mapping:', len(input_tokenizer.word_index))\n",
    "pprint(truncate_dict(input_tokenizer.word_index))\n",
    "print('Number of entries in output mapping:', len(output_tokenizer.word_index))\n",
    "pprint(truncate_dict(output_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map input and output texts to integer sequences using the tokenizers, then pad and truncate the sequences to desired input and output lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Paranthropus\n",
      "Sequence: [19, 1, 3, 1, 4, 10, 13, 3, 6, 19, 15, 9]\n",
      "Padded: [19  1  3  1  4 10 13  3  6 19 15  9  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['p', 'a', 'r', 'a', 'n', 't', 'h', 'r', 'o', 'p', 'u', 's', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "Text: パラントロプス\n",
      "Sequence: [52, 9, 4, 10, 18, 48, 6]\n",
      "Padded: [52  9  4 10 18 48  6  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['パ', 'ラ', 'ン', 'ト', 'ロ', 'プ', 'ス', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "type(encoder_X): <class 'numpy.ndarray'>\n",
      "encoder_X.shape: (100000, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def vectorize(texts, tokenizer, maxlen, quiet=False):\n",
    "    # This bit does the work\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "    \n",
    "    # This just prints out the first input and its vectorized versions\n",
    "    if not quiet:\n",
    "        print('Text:', texts[0])\n",
    "        print('Sequence:', sequences[0])\n",
    "        print('Padded:', padded[0])\n",
    "        print('Mapped back:', [tokenizer.index_word.get(i, '-') for i in padded[0]])\n",
    "    \n",
    "    return padded\n",
    "\n",
    "\n",
    "encoder_X = vectorize(input_texts, input_tokenizer, INPUT_LENGTH)\n",
    "decoder_Y = vectorize(output_texts, output_tokenizer, OUTPUT_LENGTH)\n",
    "\n",
    "# This creates numpy arrays:\n",
    "print('type(encoder_X):', type(encoder_X))\n",
    "print('encoder_X.shape:', encoder_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In prediction, the decoder will receive its last output as input at each timestep. During training, we'll use _teacher forcing_, where the decoder is instead given the correct previous input. To implement this, the output sequence (`decoder_Y`) is shifted one character forward, and the special start symbol is placed first in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_X: [ 1 52  9  4 10 18 48  6  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['<START>', 'パ', 'ラ', 'ン', 'ト', 'ロ', 'プ', 'ス', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "decoder_Y: [52  9  4 10 18 48  6  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['パ', 'ラ', 'ン', 'ト', 'ロ', 'プ', 'ス', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "decoder_X = np.zeros_like(decoder_Y)\n",
    "decoder_X[:,1:] = decoder_Y[:,:-1]\n",
    "decoder_X[:,0] = START_INDEX\n",
    "\n",
    "print('decoder_X:', decoder_X[0])\n",
    "print('Mapped back:', [output_tokenizer.index_word.get(i, '-') for i in decoder_X[0]])\n",
    "print('decoder_Y:', decoder_Y[0])\n",
    "print('Mapped back:', [output_tokenizer.index_word.get(i, '-') for i in decoder_Y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert output integer values standing for vocabulary items (characters) into a one-hot representation for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_Y[0][0]: 52\n",
      "one_hot_decoder_Y[0][0]:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "one_hot_decoder_Y[0][0].argmax(): 52\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "one_hot_decoder_Y = to_categorical(decoder_Y)\n",
    "\n",
    "print('decoder_Y[0][0]:', decoder_Y[0][0])\n",
    "print('one_hot_decoder_Y[0][0]:')\n",
    "print(one_hot_decoder_Y[0][0])\n",
    "print('one_hot_decoder_Y[0][0].argmax():', one_hot_decoder_Y[0][0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Note the following:\n",
    "\n",
    "* `mask_zero=True` for the embedding makes the model ignore padding (see [Masking and padding with Keras](https://www.tensorflow.org/guide/keras/masking_and_padding))\n",
    "* `return_state=True` for the encoder RNN returns the state of the last timestep in addition to output (see https://keras.io/layers/recurrent/).\n",
    "* As we're using an LSTM, we get two separate state values, _h_ and _c_ (see below)\n",
    "* `return_sequences=True` for the decoder RNN returns the output from each time step, not only the last\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" style=\"width: 50%\">\n",
    "\n",
    "(LSTM illustration from https://colah.github.io/posts/2015-08-Understanding-LSTMs/ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 100)      13500       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 100)      8900        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100), (None, 80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 20, 100)      80400       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 20, 89)       8989        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 192,189\n",
      "Trainable params: 192,189\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "\n",
    "def build_seq2seq_model(input_length, output_length,\n",
    "                        input_vocab_size, output_vocab_size,\n",
    "                        embedding_dim=EMBEDDING_DIM, rnn_units=RNN_UNITS):\n",
    "    encoder_input = Input(shape=(input_length,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, embedding_dim, mask_zero=True)(encoder_input)\n",
    "    encoder_output, encoder_h, encoder_c = LSTM(\n",
    "        rnn_units,\n",
    "        return_sequences=False,\n",
    "        return_state=True\n",
    "    )(encoder_embedding)\n",
    "    encoder_states = [encoder_h, encoder_c]\n",
    "\n",
    "    decoder_input = Input(shape=(output_length,))\n",
    "    decoder_embedding = Embedding(output_vocab_size, embedding_dim, mask_zero=True)(decoder_input)\n",
    "    decoder_rnn = LSTM(rnn_units, return_sequences=True)(\n",
    "        decoder_embedding,\n",
    "        initial_state=encoder_states\n",
    "    )\n",
    "    decoder_output = TimeDistributed(Dense(output_vocab_size, activation=\"softmax\"))(decoder_rnn)\n",
    "\n",
    "    model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_seq2seq_model(\n",
    "    input_length=INPUT_LENGTH,\n",
    "    output_length=OUTPUT_LENGTH,\n",
    "    input_vocab_size=INPUT_VOCAB_SIZE,\n",
    "    output_vocab_size=OUTPUT_VOCAB_SIZE\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As we have one-hot encoded our outputs, we'll use `categorical_crossentropy` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/5\n",
      "80000/80000 [==============================] - 130s 2ms/sample - loss: 1.3628 - acc: 0.3045 - val_loss: 1.0712 - val_acc: 0.4125\n",
      "Epoch 2/5\n",
      "80000/80000 [==============================] - 141s 2ms/sample - loss: 0.9076 - acc: 0.4981 - val_loss: 0.7869 - val_acc: 0.5587\n",
      "Epoch 3/5\n",
      "80000/80000 [==============================] - 273s 3ms/sample - loss: 0.7202 - acc: 0.5957 - val_loss: 0.6630 - val_acc: 0.6259\n",
      "Epoch 4/5\n",
      "80000/80000 [==============================] - 301s 4ms/sample - loss: 0.6234 - acc: 0.6500 - val_loss: 0.5926 - val_acc: 0.6682\n",
      "Epoch 5/5\n",
      "80000/80000 [==============================] - 325s 4ms/sample - loss: 0.5651 - acc: 0.6842 - val_loss: 0.5500 - val_acc: 0.6908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[encoder_X, decoder_X], \n",
    "    y=[one_hot_decoder_Y],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.41250822, 0.55866325, 0.62591743, 0.66817546, 0.6908017]\n",
      "Max accuracy: 0.6908017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    train_metric = 'acc' if 'acc' in history.history else 'accuracy'\n",
    "    val_metric = 'val_acc' if 'val_acc' in history.history else 'val_accuracy'\n",
    "    print(\"History:\", history.history[val_metric])\n",
    "    print(\"Max accuracy:\", max(history.history[val_metric]))\n",
    "    y_min = min(history.history[train_metric] + history.history[val_metric])\n",
    "    y_max = max(history.history[train_metric] + history.history[val_metric])\n",
    "    plt.ylim(max(y_min-0.1, 0.0), min(y_max+0.1, 1.0))\n",
    "    plt.plot(history.history[val_metric],label=\"Validation set accuracy\")\n",
    "    plt.plot(history.history[train_metric],label=\"Training set accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be leveling out a bit, but improving still with no signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "For prediction, we'll vectorize the given text normally, and initialize the decoder inputs to a vector with an initial start symbol and zeros otherwise.\n",
    "\n",
    "We'll then predict outputs, take the first new predicted character, place that back into the decoder inputs, and iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encoder_X = vectorize([text], input_tokenizer, INPUT_LENGTH, quiet=True)\n",
    "    decoder_X = np.zeros(shape=(1, OUTPUT_LENGTH))\n",
    "    decoder_X[0,0] = START_INDEX\n",
    "    predictions = []\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        prediction = model.predict([encoder_X, decoder_X])[0][i].argmax()\n",
    "        predictions.append(prediction)\n",
    "        decoder_X[0,i] = prediction\n",
    "    pred_chars = []\n",
    "    for i in predictions:\n",
    "        if i == 0:\n",
    "            break\n",
    "        pred_chars += output_tokenizer.index_word[i]\n",
    "    return ''.join(pred_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a few cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James ジェームズ\n",
      "John ジョン\n",
      "Robert ロベルト\n",
      "Mary マリー\n",
      "Patricia パトリアイ\n",
      "Linda リンダ\n"
     ]
    }
   ],
   "source": [
    "test_inputs = ['James', 'John', 'Robert', 'Mary', 'Patricia', 'Linda']\n",
    "for text in test_inputs:\n",
    "    print(text, predict(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
