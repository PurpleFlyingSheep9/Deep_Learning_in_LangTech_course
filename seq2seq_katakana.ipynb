{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-sequence RNN\n",
    "\n",
    "This notebook shows an example of a character-level sequence-to-sequence recurrent neural network model using Keras.\n",
    "\n",
    "The implementation and example data draw on [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) and [English to Katakana using a Sequence-to-Sequence model](https://github.com/wanasit/katakana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The following variables configure a few aspects of the data, model, and training process. To adapt this example to a different dataset, you'll probably want to change these to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of examples to read\n",
    "MAX_EXAMPLES = 100000\n",
    "\n",
    "# Maximum length of input sequence in characters\n",
    "INPUT_LENGTH = 20\n",
    "\n",
    "# Maximum length of output sequence in characters\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "# Number of epochs to train for\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Size of character embeddings\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Size of RNN states\n",
    "RNN_UNITS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "We'll be using the English to Japanese katakana characters dataset from [English to Katakana using a Sequence-to-Sequence model](https://github.com/wanasit/katakana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data.csv’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/wanasit/katakana/master/dataset/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paranthropus → パラントロプス\n",
      "Jarret Martin → ジャレット・マーティン\n",
      "Ildefons Lima → イルデフォンス・リマ・ソラ\n",
      "Joseph Calleia → ジョセフ・カレイア\n",
      "Rorschach → ロールシャッハ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def load_data(fn, separator=',', has_header_line=True, max_examples=None):\n",
    "    data = []\n",
    "    with open(fn) as f:\n",
    "        if has_header_line:\n",
    "            next(f)    # skip header\n",
    "        for line in f:\n",
    "            if max_examples is not None and len(data) >= max_examples:\n",
    "                break\n",
    "            line = line.rstrip('\\n')\n",
    "            input_text, output_text = line.split(separator)\n",
    "            data.append([input_text, output_text])\n",
    "    return data\n",
    "\n",
    "\n",
    "data = load_data('data.csv', max_examples=MAX_EXAMPLES)\n",
    "\n",
    "random.seed(1234)    # make random.shuffle() repeatable\n",
    "random.shuffle(data)\n",
    "\n",
    "input_texts = [input_text for input_text, output_text in data]\n",
    "output_texts = [output_text for input_text, output_text in data]\n",
    "\n",
    "\n",
    "# Have a look at the source data\n",
    "for i in range(5):\n",
    "    print(input_texts[i], '→', output_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize on the character level with lowercasing. To allow different input and output alphabets, create separate tokenizers for each.\n",
    "\n",
    "We're slightly abusing the tokenizer's out-of-vocabulary item support here to introduce a special `<START>` token into the mapping. As we're not restricting the number of words, this token will never be output by the tokenizer, so we're free to use it for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "input_tokenizer = Tokenizer(lower=True, char_level=True)\n",
    "output_tokenizer = Tokenizer(lower=True, char_level=True, oov_token='<START>')\n",
    "\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "output_tokenizer.fit_on_texts(output_texts)\n",
    "\n",
    "# Remember these\n",
    "INPUT_VOCAB_SIZE = max(input_tokenizer.word_index.values()) + 1\n",
    "OUTPUT_VOCAB_SIZE = max(output_tokenizer.word_index.values()) + 1\n",
    "START_INDEX = output_tokenizer.word_index['<START>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at those mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in input mapping: 134\n",
      "{' ': 7,\n",
      " 'a': 1,\n",
      " 'e': 2,\n",
      " 'i': 5,\n",
      " 'l': 8,\n",
      " 'n': 4,\n",
      " 'o': 6,\n",
      " 'r': 3,\n",
      " 's': 9,\n",
      " 't': 10}\n",
      "Number of entries in output mapping: 88\n",
      "{'<START>': 1,\n",
      " 'ア': 8,\n",
      " 'ス': 6,\n",
      " 'ト': 10,\n",
      " 'ラ': 9,\n",
      " 'リ': 7,\n",
      " 'ル': 5,\n",
      " 'ン': 4,\n",
      " '・': 3,\n",
      " 'ー': 2}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint    # pretty-printer\n",
    "\n",
    "\n",
    "def truncate_dict(d, count=10):\n",
    "    # Returns at most count items from the given dictionary.  \n",
    "    return dict(i for i, _ in zip(d.items(), range(count)))\n",
    "\n",
    "\n",
    "print('Number of entries in input mapping:', len(input_tokenizer.word_index))\n",
    "pprint(truncate_dict(input_tokenizer.word_index))\n",
    "print('Number of entries in output mapping:', len(output_tokenizer.word_index))\n",
    "pprint(truncate_dict(output_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map input and output texts to integer sequences using the tokenizers, then pad and truncate the sequences to desired input and output lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Paranthropus\n",
      "Sequence: [19, 1, 3, 1, 4, 10, 13, 3, 6, 19, 15, 9]\n",
      "Padded: [19  1  3  1  4 10 13  3  6 19 15  9  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['p', 'a', 'r', 'a', 'n', 't', 'h', 'r', 'o', 'p', 'u', 's', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "Text: パラントロプス\n",
      "Sequence: [52, 9, 4, 10, 18, 48, 6]\n",
      "Padded: [52  9  4 10 18 48  6  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['パ', 'ラ', 'ン', 'ト', 'ロ', 'プ', 'ス', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "type(encoder_X): <class 'numpy.ndarray'>\n",
      "encoder_X.shape: (100000, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def vectorize(texts, tokenizer, maxlen, quiet=False):\n",
    "    # This bit does the work\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "    \n",
    "    # This just prints out the first input and its vectorized versions\n",
    "    if not quiet:\n",
    "        print('Text:', texts[0])\n",
    "        print('Sequence:', sequences[0])\n",
    "        print('Padded:', padded[0])\n",
    "        print('Mapped back:', [tokenizer.index_word.get(i, '-') for i in padded[0]])\n",
    "    \n",
    "    return padded\n",
    "\n",
    "\n",
    "encoder_X = vectorize(input_texts, input_tokenizer, INPUT_LENGTH)\n",
    "decoder_Y = vectorize(output_texts, output_tokenizer, OUTPUT_LENGTH)\n",
    "\n",
    "# This creates numpy arrays:\n",
    "print('type(encoder_X):', type(encoder_X))\n",
    "print('encoder_X.shape:', encoder_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In prediction, the decoder will receive its last output as input at each timestep. During training, we'll use _teacher forcing_, where the decoder is instead given the correct previous output. To implement this, the output sequence (`decoder_Y`) is shifted one character forward, and the special start symbol is placed first in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_X: [ 1 52  9  4 10 18 48  6  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['<START>', 'パ', 'ラ', 'ン', 'ト', 'ロ', 'プ', 'ス', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "decoder_Y: [52  9  4 10 18 48  6  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['パ', 'ラ', 'ン', 'ト', 'ロ', 'プ', 'ス', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "decoder_X = np.zeros_like(decoder_Y)\n",
    "decoder_X[:,1:] = decoder_Y[:,:-1]\n",
    "decoder_X[:,0] = START_INDEX\n",
    "\n",
    "print('decoder_X:', decoder_X[0])\n",
    "print('Mapped back:', [output_tokenizer.index_word.get(i, '-') for i in decoder_X[0]])\n",
    "print('decoder_Y:', decoder_Y[0])\n",
    "print('Mapped back:', [output_tokenizer.index_word.get(i, '-') for i in decoder_Y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert output integer values standing for vocabulary items (characters) into a one-hot representation for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_Y[0][0]: 52\n",
      "one_hot_decoder_Y[0][0]:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "one_hot_decoder_Y[0][0].argmax(): 52\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "one_hot_decoder_Y = to_categorical(decoder_Y)\n",
    "\n",
    "print('decoder_Y[0][0]:', decoder_Y[0][0])\n",
    "print('one_hot_decoder_Y[0][0]:')\n",
    "print(one_hot_decoder_Y[0][0])\n",
    "print('one_hot_decoder_Y[0][0].argmax():', one_hot_decoder_Y[0][0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Note the following:\n",
    "\n",
    "* `mask_zero=True` for the embedding makes the model ignore padding (see [Masking and padding with Keras](https://www.tensorflow.org/guide/keras/masking_and_padding))\n",
    "* `return_state=True` for the encoder RNN returns the state of the last timestep in addition to output (see https://keras.io/layers/recurrent/).\n",
    "* As we're using an LSTM, we get two separate state values, _h_ and _c_ (see below)\n",
    "* `return_sequences=True` for the decoder RNN returns the output from each time step, not only the last\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" style=\"width: 50%\">\n",
    "\n",
    "(LSTM illustration from https://colah.github.io/posts/2015-08-Understanding-LSTMs/ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 100)      13500       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 100)      8900        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100), (None, 80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 20, 100)      80400       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 20, 89)       8989        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 192,189\n",
      "Trainable params: 192,189\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "\n",
    "def build_seq2seq_model(input_length, output_length,\n",
    "                        input_vocab_size, output_vocab_size,\n",
    "                        embedding_dim=EMBEDDING_DIM, rnn_units=RNN_UNITS):\n",
    "    encoder_input = Input(shape=(input_length,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, embedding_dim, mask_zero=True)(encoder_input)\n",
    "    encoder_output, encoder_h, encoder_c = LSTM(\n",
    "        rnn_units,\n",
    "        return_sequences=False,\n",
    "        return_state=True\n",
    "    )(encoder_embedding)\n",
    "    encoder_states = [encoder_h, encoder_c]\n",
    "\n",
    "    decoder_input = Input(shape=(output_length,))\n",
    "    decoder_embedding = Embedding(output_vocab_size, embedding_dim, mask_zero=True)(decoder_input)\n",
    "    decoder_rnn = LSTM(rnn_units, return_sequences=True)(\n",
    "        decoder_embedding,\n",
    "        initial_state=encoder_states\n",
    "    )\n",
    "    decoder_output = TimeDistributed(Dense(output_vocab_size, activation=\"softmax\"))(decoder_rnn)\n",
    "\n",
    "    model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_seq2seq_model(\n",
    "    input_length=INPUT_LENGTH,\n",
    "    output_length=OUTPUT_LENGTH,\n",
    "    input_vocab_size=INPUT_VOCAB_SIZE,\n",
    "    output_vocab_size=OUTPUT_VOCAB_SIZE\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As we have one-hot encoded our outputs, we'll use `categorical_crossentropy` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/5\n",
      "80000/80000 [==============================] - 136s 2ms/sample - loss: 1.3681 - val_loss: 1.0863\n",
      "Epoch 2/5\n",
      "80000/80000 [==============================] - 120s 2ms/sample - loss: 0.9072 - val_loss: 0.7752\n",
      "Epoch 3/5\n",
      "80000/80000 [==============================] - 129s 2ms/sample - loss: 0.7090 - val_loss: 0.6532\n",
      "Epoch 4/5\n",
      "80000/80000 [==============================] - 105s 1ms/sample - loss: 0.6180 - val_loss: 0.5903\n",
      "Epoch 5/5\n",
      "80000/80000 [==============================] - 106s 1ms/sample - loss: 0.5607 - val_loss: 0.5431\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[encoder_X, decoder_X], \n",
    "    y=[one_hot_decoder_Y],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'],label=\"Training set loss\")\n",
    "    plt.plot(history.history['val_loss'],label=\"Validation set loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be leveling out a bit, but improving still with no signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "For prediction, we'll vectorize the given text normally, and initialize the decoder inputs to a vector with an initial start symbol and zeros otherwise.\n",
    "\n",
    "We'll then predict outputs, take the first new predicted character, place that back into the decoder inputs, and iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encoder_X = vectorize([text], input_tokenizer, INPUT_LENGTH, quiet=True)\n",
    "    decoder_X = np.zeros(shape=(1, OUTPUT_LENGTH))\n",
    "    decoder_X[0,0] = START_INDEX\n",
    "    predictions = []\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        prediction = model.predict([encoder_X, decoder_X])[0][i].argmax()\n",
    "        predictions.append(prediction)\n",
    "        decoder_X[0,i] = prediction\n",
    "    pred_chars = []\n",
    "    for i in predictions:\n",
    "        if i == 0:\n",
    "            break\n",
    "        pred_chars += output_tokenizer.index_word[i]\n",
    "    return ''.join(pred_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a few cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James ジェームズ\n",
      "John ジョン\n",
      "Robert ロベート\n",
      "Mary マリー\n",
      "Patricia パトリシア\n",
      "Linda リンダ\n"
     ]
    }
   ],
   "source": [
    "test_inputs = ['James', 'John', 'Robert', 'Mary', 'Patricia', 'Linda']\n",
    "for text in test_inputs:\n",
    "    print(text, predict(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
