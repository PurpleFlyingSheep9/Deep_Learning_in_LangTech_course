{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Named entity recognition</h2>\n",
    "<br>\n",
    "Sequence labelling: input word sequence, output tag sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ner.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load CoNLL'03 data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the CoNLL'03 dataset. The data in their original format can be found here https://github.com/glample/tagger .<br><br>\n",
    "\n",
    "In this demo, the dataset has already been converted to json files. The converted data are found here under the file names `ner_train.json` and `ner_test.json`: https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/tree/master/data The code used for convertion can be found here: https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/read_ner.ipynb <br><br>\n",
    "\n",
    "The data is divided into separate sentences and has also been tokenized already. You don't have to do any preprocessing. The produced json files contain a single dictionary for each sentence. The dictionary has a list of tokens and the corresponding list of labels, e.g.: { \"text\": [ \"EU\", \"rejects\", \"German\", \"call\", \"to\", \"boycott\", \"British\", \"lamb\", \".\" ], \"tags\": [ \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['text', 'tags'])\n",
      "{'text': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'tags': ['I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"data/ner_train.json\") as f:\n",
    "    data=json.load(f)\n",
    "\n",
    "    \n",
    "# Look at the data\n",
    "print(type(data))\n",
    "print(type(data[0]))\n",
    "print(data[0].keys())\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['9/16', '-', 'Luo', 'Yigang', '(', 'China', ')', 'beat', 'Jason', 'Wong', '(', 'Malaysia', ')', '15-5', '15-6']\n",
      "Label: ['O', 'O', 'I-PER', 'I-PER', 'O', 'I-LOC', 'O', 'O', 'I-PER', 'I-PER', 'O', 'I-LOC', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy\n",
    "\n",
    "\n",
    "random.seed(123)    # This makes the shuffle produce the same order every time\n",
    "random.shuffle(data)\n",
    "\n",
    "texts=[example[\"text\"] for example in data]\n",
    "labels=[example[\"tags\"] for example in data]\n",
    "\n",
    "# Example text and labels\n",
    "print('Text:', texts[0])\n",
    "print('Label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do the same thing for the validation data\n",
    "# We use a separate validation set, since generally using sentences from the same documents as train/validation results in overly optimistic scores\n",
    "with open(\"data/ner_test.json\") as f:\n",
    "    validation_data=json.load(f)\n",
    "validation_texts=[example[\"text\"] for example in validation_data]\n",
    "validation_labels=[example[\"tags\"] for example in validation_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load pretrained embeddings</h3>\n",
    "<br>\n",
    "We use gensim to read the embedding model.<br>\n",
    "Note that we are using a vocabulary size of only 50,000 so that the model trains quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 50000\n",
      "First 50 words: [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':', ')', 'that', '(', 'is', 'for', 'on', '*', 'with', 'as', 'it', 'The', 'or', 'was', \"'\", \"'s\", 'by', 'from', 'at', 'I', 'this', 'you', '/', 'are', '=', 'not', '-', 'have', '?', 'be', 'which', ';', 'all', 'his', 'has', 'one', 'their', 'about', 'but', 'an', '|']\n",
      "Before normalization: [-0.0234 -0.0268 -0.0838  0.0386 -0.0321  0.0628  0.0281 -0.0252  0.0269\n",
      " -0.0063]\n",
      "After normalization: [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "vector_model = KeyedVectors.load_word2vec_format(\"data/wiki-news-300d-1M.vec\", binary=False, limit=50000)\n",
    "\n",
    "\n",
    "# sort based on the index to make sure they are in the correct order\n",
    "words=[k for k,v in sorted(vector_model.vocab.items(), key=lambda x:x[1].index)]\n",
    "print(\"Words from embedding model:\",len(words))\n",
    "print(\"First 50 words:\",words[:50])\n",
    "\n",
    "# Normalize the vectors to unit length\n",
    "print(\"Before normalization:\",vector_model.get_vector(\"in\")[:10])\n",
    "vector_model.init_sims(replace=True)\n",
    "print(\"After normalization:\",vector_model.get_vector(\"in\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocabulary: 50002\n",
      "Found pretrained vectors for 50000 words.\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary mappings\n",
    "\n",
    "vocabulary={\"<SPECIAL>\": 0, \"<OOV>\": 1} # zero has a special meaning in sequence models, prevent using it for a normal word\n",
    "for word in words: #these are words from the word2vec model\n",
    "    vocabulary.setdefault(word, len(vocabulary))\n",
    "\n",
    "print(\"Words in vocabulary:\",len(vocabulary))\n",
    "inversed_vocabulary={value:key for key, value in vocabulary.items()} # inverse the dictionary\n",
    "    \n",
    "                \n",
    "# Embedding matrix\n",
    "def load_pretrained_embeddings(vocab, embedding_model):\n",
    "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
    "    pretrained_embeddings=numpy.random.uniform(low=-0.05, high=0.05, size=(len(vocab)-1,embedding_model.vectors.shape[1]))\n",
    "    pretrained_embeddings = numpy.vstack((numpy.zeros(shape=(1,embedding_model.vectors.shape[1])), pretrained_embeddings))\n",
    "    found=0\n",
    "    for word,idx in vocab.items():\n",
    "        if word in embedding_model.vocab:\n",
    "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
    "            found+=1\n",
    "            \n",
    "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
    "    return pretrained_embeddings\n",
    "\n",
    "pretrained=load_pretrained_embeddings(vocabulary, vector_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocess data</h3>\n",
    "<br>\n",
    "Both the text and the labels are strings; we'll need to convert the labels into integers and the text into an appropriate format for RNN training.<br>\n",
    "<h4>Labels</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-LOC': 0, 'I-ORG': 2, 'I-PER': 1, 'O': 3}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Label mappings\n",
    "# 1) gather a set of unique labels\n",
    "label_set = set()\n",
    "for sentence_labels in labels: #loops over sentences \n",
    "    for label in sentence_labels: #loops over labels in one sentence\n",
    "        label_set.add(label)\n",
    "# 2) index these\n",
    "label_map = {}\n",
    "for index, label in enumerate(label_set):\n",
    "    label_map[label]=index\n",
    "    \n",
    "pprint(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 1, 1, 3, 0, 3, 3, 1, 1, 3, 0, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# vectorize the labels\n",
    "def label_vectorizer(labels,label_map):\n",
    "    vectorized_labels = []\n",
    "    for label in labels:\n",
    "        vectorized_example_label = []\n",
    "        for token in label:\n",
    "            vectorized_example_label.append(label_map[token])\n",
    "        vectorized_labels.append(vectorized_example_label)\n",
    "    vectorized_labels = numpy.array(vectorized_labels)\n",
    "    return vectorized_labels\n",
    "        \n",
    "\n",
    "vectorized_labels = label_vectorizer(labels,label_map)\n",
    "validation_vectorized_labels = label_vectorizer(validation_labels,label_map)\n",
    "\n",
    "pprint(vectorized_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Texts</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the vectorization of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9/16',\n",
      " '-',\n",
      " 'Luo',\n",
      " 'Yigang',\n",
      " '(',\n",
      " 'China',\n",
      " ')',\n",
      " 'beat',\n",
      " 'Jason',\n",
      " 'Wong',\n",
      " '(',\n",
      " 'Malaysia',\n",
      " ')',\n",
      " '15-5',\n",
      " '15-6']\n",
      "[1, 37, 32297, 1, 14, 398, 12, 2270, 4292, 12601, 14, 3826, 12, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def text_vectorizer(vocab, texts):\n",
    "    vectorized_data = [] # turn text into numbers based on our vocabulary mapping\n",
    "    sentence_lengths = [] # Number of tokens in each sentence\n",
    "    \n",
    "    for i, one_example in enumerate(texts):\n",
    "        vectorized_example = []\n",
    "        for word in one_example:\n",
    "            vectorized_example.append(vocab.get(word, 1)) # 1 is our index for out-of-vocabulary tokens\n",
    "\n",
    "        vectorized_data.append(vectorized_example)     \n",
    "        sentence_lengths.append(len(one_example))\n",
    "        \n",
    "    vectorized_data = numpy.array(vectorized_data) # turn python list into numpy array\n",
    "    \n",
    "    return vectorized_data, sentence_lengths\n",
    "\n",
    "vectorized_data, lengths=text_vectorizer(vocabulary, texts)\n",
    "validation_vectorized_data, validation_lengths=text_vectorizer(vocabulary, validation_texts)\n",
    "\n",
    "pprint(texts[0])\n",
    "pprint(vectorized_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are a lot of out-of-vocabulary tokens because of the small vocabulary we use. The number of `<OOV>` tokens can be decreased by using a larger vocabulary.<br><br>\n",
    "We have to pad the sequences so that all of them are of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape: (14041,)\n",
      "New shape: (14041, 113)\n",
      "First example: [    1    37 32297     1    14   398    12  2270  4292 12601    14  3826\n",
      "    12     1     1     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "Padded labels shape: (14041, 113, 1)\n",
      "{'I-LOC': 0, 'I-ORG': 2, 'I-PER': 1, 'O': 3}\n",
      "First example labels:\n",
      "array([[3],\n",
      "       [3],\n",
      "       [1],\n",
      "       [1],\n",
      "       [3],\n",
      "       [0],\n",
      "       [3],\n",
      "       [3],\n",
      "       [1],\n",
      "       [1],\n",
      "       [3],\n",
      "       [0],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]], dtype=int32)\n",
      "First weight vector: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "### Only needed for me, not to block the whole GPU, you don't need this stuff\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "### ---end of weird stuff\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Old shape:\", vectorized_data.shape)\n",
    "vectorized_data_padded=pad_sequences(vectorized_data, padding='post', maxlen=max(lengths))\n",
    "print(\"New shape:\", vectorized_data_padded.shape)\n",
    "print(\"First example:\", vectorized_data_padded[0])\n",
    "# Even with the sparse output format, the shape has to be similar to the one-hot encoding\n",
    "vectorized_labels_padded=numpy.expand_dims(pad_sequences(vectorized_labels, padding='post', maxlen=max(lengths)), -1)\n",
    "print(\"Padded labels shape:\", vectorized_labels_padded.shape)\n",
    "pprint(label_map)\n",
    "print(\"First example labels:\")\n",
    "pprint(vectorized_labels_padded[0])\n",
    "\n",
    "weights = numpy.copy(vectorized_data_padded)\n",
    "weights[weights > 0] = 1\n",
    "print(\"First weight vector:\", weights[0])\n",
    "\n",
    "# Same stuff for the validation data\n",
    "validation_vectorized_data_padded=pad_sequences(validation_vectorized_data, padding='post', maxlen=max(lengths))\n",
    "validation_vectorized_labels_padded=numpy.expand_dims(pad_sequences(validation_vectorized_labels, padding='post',maxlen=max(lengths)), -1)\n",
    "validation_weights = numpy.copy(validation_vectorized_data_padded)\n",
    "validation_weights[validation_weights > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluation function</h4>\n",
    "<br>\n",
    "The entities can continue beyond one token so the model has to evaluate predictions based on that. We write a function that converts the sequence of tokens into entities. We then write another function that calculates precision, recall, and f-score based on the predictions. We put these functions into a custom callback which we use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "def _convert_to_entities(input_sequence):\n",
    "    \"\"\"\n",
    "    Reads a sequence of tags and converts them into a set of entities.\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    previous_tag = label_map['O']\n",
    "    for i, tag in enumerate(input_sequence):\n",
    "        if tag != previous_tag and tag != label_map['O']: # New entity starts\n",
    "            if len(current_entity) > 0:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = []\n",
    "            current_entity.append((tag, i))\n",
    "        elif tag == label_map['O']: # Entity has ended\n",
    "            if len(current_entity) > 0:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = []\n",
    "        elif tag == previous_tag: # Current entity continues\n",
    "            current_entity.append((tag, i))\n",
    "        previous_tag = tag\n",
    "    \n",
    "    # Add the last entity to our entity list if the sentences ends with an entity\n",
    "    if len(current_entity) > 0:\n",
    "        entities.append(current_entity)\n",
    "    \n",
    "    entity_offsets = set()\n",
    "    \n",
    "    for e in entities:\n",
    "        entity_offsets.add((e[0][0], e[0][1], e[-1][1]+1))\n",
    "    return entity_offsets\n",
    "\n",
    "def _entity_level_PRF(predictions, gold, lengths):\n",
    "    pred_entities = [_convert_to_entities(labels[:lengths[i]]) for i, labels in enumerate(predictions)]\n",
    "    gold_entities = [_convert_to_entities(labels[:lengths[i], 0]) for i, labels in enumerate(gold)]\n",
    "    \n",
    "    tp = sum([len(pe.intersection(gold_entities[i])) for i, pe in enumerate(pred_entities)])\n",
    "    pred_count = sum([len(e) for e in pred_entities])\n",
    "    \n",
    "    try:\n",
    "        precision = tp / pred_count # tp / (tp+np)\n",
    "        recall = tp / sum([len(e) for e in gold_entities])\n",
    "        fscore = 2 * precision * recall / (precision + recall)\n",
    "    except Exception as e:\n",
    "        precision, recall, fscore = 0.0, 0.0, 0.0\n",
    "    print('\\nPrecision/Recall/F-score: %s / %s / %s' % (precision, recall, fscore))\n",
    "    return precision, recall, fscore             \n",
    "\n",
    "def evaluate(predictions, gold, lengths):\n",
    "    precision, recall, fscore = _entity_level_PRF(predictions, gold, lengths)\n",
    "    return precision, recall, fscore\n",
    "\n",
    "class EvaluateEntities(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.fscore = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        pred = numpy.argmax(self.model.predict(validation_vectorized_data_padded), axis=-1)\n",
    "        evaluation_parameters=evaluate(pred, validation_vectorized_labels_padded, validation_lengths)\n",
    "        self.precision.append(evaluation_parameters[0])\n",
    "        self.recall.append(evaluation_parameters[1])\n",
    "        self.fscore.append(evaluation_parameters[2])\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predicting word labels with word embeddings</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into RNNs, we first build a simpler model without any recurrent layers:\n",
    "<br>\n",
    "- input: sequence of `sequence_length` integers corresponding to words<br>\n",
    "- embedding: pretrained mapping from integers to `vector_size`-dimensional vectors<br>\n",
    "- hidden: `hidden_size`-dimensional fully connected layer with relu activation<br>\n",
    "- output: `class_count`-dimensional fully connected layer with softmax activation<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Activation, TimeDistributed\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "example_count, sequence_len = vectorized_data_padded.shape\n",
    "class_count = len(label_set)\n",
    "hidden_size = 100\n",
    "\n",
    "vector_size= pretrained.shape[1]\n",
    "\n",
    "def build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained):\n",
    "    inp=Input(shape=(sequence_len,))\n",
    "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
    "    hidden = TimeDistributed(Dense(hidden_size, activation=\"relu\"))(embeddings) # We change this activation function\n",
    "    outp = TimeDistributed(Dense(class_count, activation=\"softmax\"))(hidden)\n",
    "    return Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "model = build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 113)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 113, 300)          15000600  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 113, 100)          30100     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 113, 4)            404       \n",
      "=================================================================\n",
      "Total params: 15,031,104\n",
      "Trainable params: 30,504\n",
      "Non-trainable params: 15,000,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train the model</h3>\n",
    "<br>\n",
    "We'll then compile and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss: 4.0644\n",
      "\n",
      "Precision/Recall/F-score: 0.5975250441956393 / 0.40398406374501994 / 0.48205371999049207\n",
      "Epoch 2/10\n",
      " - 4s - loss: 1.7845\n",
      "\n",
      "Precision/Recall/F-score: 0.5578542217945633 / 0.46195219123505976 / 0.5053939195815625\n",
      "Epoch 3/10\n",
      " - 4s - loss: 1.5820\n",
      "\n",
      "Precision/Recall/F-score: 0.5669759695455627 / 0.4747011952191235 / 0.5167515992627127\n",
      "Epoch 4/10\n",
      " - 4s - loss: 1.5210\n",
      "\n",
      "Precision/Recall/F-score: 0.5674789128397376 / 0.4824701195219124 / 0.5215331610680448\n",
      "Epoch 5/10\n",
      " - 4s - loss: 1.4855\n",
      "\n",
      "Precision/Recall/F-score: 0.5783695398271432 / 0.4932270916334661 / 0.5324158692613697\n",
      "Epoch 6/10\n",
      " - 4s - loss: 1.4750\n",
      "\n",
      "Precision/Recall/F-score: 0.5860771401693321 / 0.4964143426294821 / 0.5375323554788611\n",
      "Epoch 7/10\n",
      " - 4s - loss: 1.4624\n",
      "\n",
      "Precision/Recall/F-score: 0.5821244735610669 / 0.4956175298804781 / 0.53539918226813\n",
      "Epoch 8/10\n",
      " - 4s - loss: 1.4447\n",
      "\n",
      "Precision/Recall/F-score: 0.5927152317880795 / 0.499203187250996 / 0.541955017301038\n",
      "Epoch 9/10\n",
      " - 4s - loss: 1.4335\n",
      "\n",
      "Precision/Recall/F-score: 0.5946137491141035 / 0.5013944223107569 / 0.5440397708851182\n",
      "Epoch 10/10\n",
      " - 4s - loss: 1.4230\n",
      "\n",
      "Precision/Recall/F-score: 0.5909728718428437 / 0.5033864541832669 / 0.5436746987951807\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(lr=0.001) # define the learning rate\n",
    "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
    "evaluation_function=EvaluateEntities()\n",
    "\n",
    "# train\n",
    "vanilla_hist=model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the f-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.48205371999049207, 0.5053939195815625, 0.5167515992627127, 0.5215331610680448, 0.5324158692613697, 0.5375323554788611, 0.53539918226813, 0.541955017301038, 0.5440397708851182, 0.5436746987951807]\n",
      "Highest f-score: 0.5440397708851182\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a2a304b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(fscores):\n",
    "    print(\"History:\", fscores)\n",
    "    print(\"Highest f-score:\", max(fscores))\n",
    "    plt.plot(fscores)\n",
    "    plt.legend(loc='lower center', borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "plot_history(evaluation_function.fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ideas to try yourself</h3>\n",
    "<br>\n",
    "Try playing around with the neural network. You could, for example, try\n",
    "- Different activation functions<br>\n",
    "- Altering the learning rate<br>\n",
    "- Use different optimizers<br>\n",
    "- Adjusting the vocabulary size of the embeddings<br>\n",
    "<br>\n",
    "Activation functions and optimizers supported by Keras can be found here: https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Including the context</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then include the context by defining and building an RNN model which has the following layers:\n",
    "<br>\n",
    "- input: sequence of `sequence_length` integers corresponding to words\n",
    "- embedding: pretrained mapping from integers to `vector_size`-dimensional vectors\n",
    "- rnn: recurrent neural network, specifically LSTM, with `rnn_size`-dimensional state\n",
    "- output: `class_count`-dimensional fully connected layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "example_count, sequence_len = vectorized_data_padded.shape\n",
    "class_count = len(label_set)\n",
    "rnn_size = 100\n",
    "\n",
    "vector_size= pretrained.shape[1]\n",
    "\n",
    "def build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained):\n",
    "    inp=Input(shape=(sequence_len,))\n",
    "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=False, trainable=False, weights=[pretrained])(inp)\n",
    "    rnn = LSTM(rnn_size, activation='relu', return_sequences=True)(embeddings)\n",
    "    outp=Dense(class_count, activation=\"softmax\")(rnn)\n",
    "    return Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "rnn_model = build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 113)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 113, 300)          15000600  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 113, 100)          30100     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 113, 4)            404       \n",
      "=================================================================\n",
      "Total params: 15,031,104\n",
      "Trainable params: 30,504\n",
      "Non-trainable params: 15,000,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train an RNN model</h3>\n",
    "<br>\n",
    "We compile and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 36s - loss: 0.6107\n",
      "\n",
      "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
      "Epoch 2/10\n",
      " - 37s - loss: 0.2983\n",
      "\n",
      "Precision/Recall/F-score: 0.700180458881155 / 0.5410358565737052 / 0.6104056635577032\n",
      "Epoch 3/10\n",
      " - 36s - loss: 0.1825\n",
      "\n",
      "Precision/Recall/F-score: 0.7224325603407478 / 0.6081673306772908 / 0.6603936837551373\n",
      "Epoch 4/10\n",
      " - 36s - loss: 0.1523\n",
      "\n",
      "Precision/Recall/F-score: 0.7101510067114094 / 0.6745019920318726 / 0.691867592970985\n",
      "Epoch 5/10\n",
      " - 39s - loss: 0.1389\n",
      "\n",
      "Precision/Recall/F-score: 0.7445462478184991 / 0.6798804780876494 / 0.7107455226988755\n",
      "Epoch 6/10\n",
      " - 39s - loss: 0.1297\n",
      "\n",
      "Precision/Recall/F-score: 0.7478184991273996 / 0.6828685258964143 / 0.7138692211578508\n",
      "Epoch 7/10\n",
      " - 37s - loss: 0.1231\n",
      "\n",
      "Precision/Recall/F-score: 0.7403663929248263 / 0.700398406374502 / 0.7198280274337191\n",
      "Epoch 8/10\n",
      " - 37s - loss: 0.1179\n",
      "\n",
      "Precision/Recall/F-score: 0.7666130144860888 / 0.6641434262948207 / 0.7117088269826021\n",
      "Epoch 9/10\n",
      " - 37s - loss: 0.1139\n",
      "\n",
      "Precision/Recall/F-score: 0.7412616339193382 / 0.7139442231075698 / 0.7273465246067986\n",
      "Epoch 10/10\n",
      " - 37s - loss: 0.1098\n",
      "\n",
      "Precision/Recall/F-score: 0.7629613356766256 / 0.6918326693227091 / 0.7256581696615126\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(lr=0.001) # define the learning rate\n",
    "rnn_model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
    "\n",
    "evaluation_function=EvaluateEntities()\n",
    "\n",
    "# train\n",
    "rnn_hist=rnn_model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the f-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.0, 0.6104056635577032, 0.6603936837551373, 0.691867592970985, 0.7107455226988755, 0.7138692211578508, 0.7198280274337191, 0.7117088269826021, 0.7273465246067986, 0.7256581696615126]\n",
      "Highest f-score: 0.7273465246067986\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49c46ab5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_history(evaluation_function.fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By including the context, our f-score increase by over 15 points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ideas to try yourself</h3>\n",
    "<br>\n",
    "Try altering the structure of the network. You could, for example<br>\n",
    "- Try different RNNs (LSTM, biLSTM)<br>\n",
    "- Try using CNNs (hint: use the Conv1D layer, and the Dense layer afterwards needs a TimeDistributed wrapper layer)<br>\n",
    "<br>\n",
    "Again, the layers supported by Keras can be found from its documentation: https://keras.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
