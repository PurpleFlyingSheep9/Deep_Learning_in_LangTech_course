{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-sequence RNN\n",
    "\n",
    "This notebook shows an example of a character-level sequence-to-sequence recurrent neural network model using Keras.\n",
    "\n",
    "The implementation draws on [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) and [English to Katakana using a Sequence-to-Sequence model](https://github.com/wanasit/katakana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The following variables configure a few aspects of the data, model, and training process. To adapt this example to a different dataset, you'll probably want to change these to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of examples to read\n",
    "MAX_EXAMPLES = 100000\n",
    "\n",
    "# Maximum length of input sequence in characters\n",
    "INPUT_LENGTH = 35\n",
    "\n",
    "# Maximum length of output sequence in characters, including start symbol\n",
    "OUTPUT_LENGTH = 11\n",
    "\n",
    "# Number of epochs to train for\n",
    "EPOCHS = 3\n",
    "\n",
    "# Training batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Size of character embeddings\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Size of RNN states\n",
    "RNN_UNITS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "We'll be using an automatically generated dataset of freeform and standardized dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘generated_dates.txt’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/TurkuNLP/Deep_Learning_in_LangTech_course/master/data/generated_dates.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max input length 35\n",
      "max output length 10\n",
      "ELOKUUN 23. 1977 → 23.08.1977\n",
      "23.10.1972 → 23.10.1972\n",
      "2006/12/22 → 22.12.2006\n",
      "1990/11/28 → 28.11.1990\n",
      "syyskuun 5. 2015 → 05.09.2015\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def load_data(fn, separator='\\t', has_header_line=False, max_examples=None):\n",
    "    data = []\n",
    "    with open(fn) as f:\n",
    "        if has_header_line:\n",
    "            next(f)    # skip header\n",
    "        for line in f:\n",
    "            if max_examples is not None and len(data) >= max_examples:\n",
    "                break\n",
    "            line = line.rstrip('\\n')\n",
    "            input_text, output_text = line.split(separator)\n",
    "            data.append([input_text, output_text])\n",
    "    return data\n",
    "\n",
    "\n",
    "data = load_data('generated_dates.txt', max_examples=MAX_EXAMPLES)\n",
    "\n",
    "random.seed(1234)    # make random.shuffle() repeatable\n",
    "random.shuffle(data)\n",
    "\n",
    "input_texts = [input_text for input_text, output_text in data]\n",
    "output_texts = [output_text for input_text, output_text in data]\n",
    "\n",
    "\n",
    "# Have a look at the source data\n",
    "print('max input length', max(len(t) for t in input_texts))\n",
    "print('max output length', max(len(t) for t in output_texts))\n",
    "for i in range(5):\n",
    "    print(input_texts[i], '→', output_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize on the character level with lowercasing. To allow different input and output alphabets, create separate tokenizers for each.\n",
    "\n",
    "We're slightly abusing the tokenizer's out-of-vocabulary item support here to introduce a special `<START>` token into the mapping. As we're not restricting the number of words, this token will never be output by the tokenizer, so we're free to use it for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "input_tokenizer = Tokenizer(lower=True, char_level=True)\n",
    "output_tokenizer = Tokenizer(lower=True, char_level=True, oov_token='<START>')\n",
    "\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "output_tokenizer.fit_on_texts(output_texts)\n",
    "\n",
    "# Remember these\n",
    "INPUT_VOCAB_SIZE = max(input_tokenizer.word_index.values()) + 1\n",
    "OUTPUT_VOCAB_SIZE = max(output_tokenizer.word_index.values()) + 1\n",
    "START_INDEX = output_tokenizer.word_index['<START>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at those mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in input mapping: 31\n",
      "{' ': 2,\n",
      " '.': 8,\n",
      " '/': 9,\n",
      " '0': 4,\n",
      " '1': 1,\n",
      " '2': 6,\n",
      " '9': 5,\n",
      " 'n': 7,\n",
      " 'u': 3,\n",
      " 'ä': 10}\n",
      "Number of entries in output mapping: 12\n",
      "{'.': 2,\n",
      " '0': 3,\n",
      " '1': 4,\n",
      " '2': 5,\n",
      " '3': 9,\n",
      " '5': 10,\n",
      " '7': 8,\n",
      " '8': 7,\n",
      " '9': 6,\n",
      " '<START>': 1}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint    # pretty-printer\n",
    "\n",
    "\n",
    "def truncate_dict(d, count=10):\n",
    "    # Returns at most count items from the given dictionary.  \n",
    "    return dict(i for i, _ in zip(d.items(), range(count)))\n",
    "\n",
    "\n",
    "print('Number of entries in input mapping:', len(input_tokenizer.word_index))\n",
    "pprint(truncate_dict(input_tokenizer.word_index))\n",
    "print('Number of entries in output mapping:', len(output_tokenizer.word_index))\n",
    "pprint(truncate_dict(output_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map input and output texts to integer sequences using the tokenizers, then pad and truncate the sequences to desired input and output lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ELOKUUN 23. 1977\n",
      "Sequence: [27, 25, 16, 11, 3, 3, 7, 2, 6, 18, 8, 2, 1, 5, 13, 13]\n",
      "Padded: [27 25 16 11  3  3  7  2  6 18  8  2  1  5 13 13  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Mapped back: ['e', 'l', 'o', 'k', 'u', 'u', 'n', ' ', '2', '3', '.', ' ', '1', '9', '7', '7', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "Text: 23.08.1977\n",
      "Sequence: [5, 9, 2, 3, 7, 2, 4, 6, 8, 8]\n",
      "Padded: [5 9 2 3 7 2 4 6 8 8 0]\n",
      "Mapped back: ['2', '3', '.', '0', '8', '.', '1', '9', '7', '7', '-']\n",
      "type(encoder_X): <class 'numpy.ndarray'>\n",
      "encoder_X.shape: (100000, 35)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def vectorize(texts, tokenizer, maxlen, quiet=False):\n",
    "    # This bit does the work\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "    \n",
    "    # This just prints out the first input and its vectorized versions\n",
    "    if not quiet:\n",
    "        print('Text:', texts[0])\n",
    "        print('Sequence:', sequences[0])\n",
    "        print('Padded:', padded[0])\n",
    "        print('Mapped back:', [tokenizer.index_word.get(i, '-') for i in padded[0]])\n",
    "    \n",
    "    return padded\n",
    "\n",
    "\n",
    "encoder_X = vectorize(input_texts, input_tokenizer, INPUT_LENGTH)\n",
    "decoder_Y = vectorize(output_texts, output_tokenizer, OUTPUT_LENGTH)\n",
    "\n",
    "# This creates numpy arrays:\n",
    "print('type(encoder_X):', type(encoder_X))\n",
    "print('encoder_X.shape:', encoder_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In prediction, the decoder will receive its last output as input at each timestep. During training, we'll use _teacher forcing_, where the decoder is instead given the correct previous input. To implement this, the output sequence (`decoder_Y`) is shifted one character forward, and the special start symbol is placed first in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_X: [1 5 9 2 3 7 2 4 6 8 8]\n",
      "Mapped back: ['<START>', '2', '3', '.', '0', '8', '.', '1', '9', '7', '7']\n",
      "decoder_Y: [5 9 2 3 7 2 4 6 8 8 0]\n",
      "Mapped back: ['2', '3', '.', '0', '8', '.', '1', '9', '7', '7', '-']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "decoder_X = np.zeros_like(decoder_Y)\n",
    "decoder_X[:,1:] = decoder_Y[:,:-1]\n",
    "decoder_X[:,0] = START_INDEX\n",
    "\n",
    "print('decoder_X:', decoder_X[0])\n",
    "print('Mapped back:', [output_tokenizer.index_word.get(i, '-') for i in decoder_X[0]])\n",
    "print('decoder_Y:', decoder_Y[0])\n",
    "print('Mapped back:', [output_tokenizer.index_word.get(i, '-') for i in decoder_Y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Note the following:\n",
    "\n",
    "* `mask_zero=True` for the embedding makes the model ignore padding (see [Masking and padding with Keras](https://www.tensorflow.org/guide/keras/masking_and_padding))\n",
    "* `return_state=True` for the encoder RNN returns the state of the last timestep in addition to output (see https://keras.io/layers/recurrent/).\n",
    "* As we're using an LSTM, we get two separate state values, _h_ and _c_ (see below)\n",
    "* `return_sequences=True` for the decoder RNN returns the output from each time step, not only the last\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" style=\"width: 50%\">\n",
    "\n",
    "(LSTM illustration from https://colah.github.io/posts/2015-08-Understanding-LSTMs/ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/smp/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 35)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 11)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 35, 100)      3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 11, 100)      1300        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100), (None, 80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 11, 100)      80400       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 11, 13)       1313        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 166,613\n",
      "Trainable params: 166,613\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "\n",
    "def build_seq2seq_model(input_length, output_length,\n",
    "                        input_vocab_size, output_vocab_size,\n",
    "                        embedding_dim=EMBEDDING_DIM, rnn_units=RNN_UNITS):\n",
    "    encoder_input = Input(shape=(input_length,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, embedding_dim, mask_zero=True)(encoder_input)\n",
    "    encoder_output, encoder_h, encoder_c = LSTM(\n",
    "        rnn_units,\n",
    "        return_sequences=False,\n",
    "        return_state=True\n",
    "    )(encoder_embedding)\n",
    "    encoder_states = [encoder_h, encoder_c]\n",
    "\n",
    "    decoder_input = Input(shape=(output_length,))\n",
    "    decoder_embedding = Embedding(output_vocab_size, embedding_dim, mask_zero=True)(decoder_input)\n",
    "    decoder_rnn = LSTM(rnn_units, return_sequences=True)(\n",
    "        decoder_embedding,\n",
    "        initial_state=encoder_states\n",
    "    )\n",
    "    decoder_output = TimeDistributed(Dense(output_vocab_size, activation=\"softmax\"))(decoder_rnn)\n",
    "\n",
    "    model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_seq2seq_model(\n",
    "    input_length=INPUT_LENGTH,\n",
    "    output_length=OUTPUT_LENGTH,\n",
    "    input_vocab_size=INPUT_VOCAB_SIZE,\n",
    "    output_vocab_size=OUTPUT_VOCAB_SIZE\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As our output values here are (as usual) integer values standing for our vocabulary items (characters), we'll use `sparse_categorical_crossentropy` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/3\n",
      "80000/80000 [==============================] - 132s 2ms/sample - loss: 0.5585 - val_loss: 0.1013\n",
      "Epoch 2/3\n",
      "80000/80000 [==============================] - 143s 2ms/sample - loss: 0.0343 - val_loss: 0.0068\n",
      "Epoch 3/3\n",
      "80000/80000 [==============================] - 124s 2ms/sample - loss: 0.0050 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[encoder_X, decoder_X], \n",
    "    y=[decoder_Y],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'],label=\"Training set loss\")\n",
    "    plt.plot(history.history['val_loss'],label=\"Validation set loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to no longer be improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "For prediction, we'll vectorize the given text normally, and initialize the decoder inputs to a vector with an initial start symbol and zeros otherwise.\n",
    "\n",
    "We'll then predict outputs, take the first new predicted character, place that back into the decoder inputs, and iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encoder_X = vectorize([text], input_tokenizer, INPUT_LENGTH, quiet=True)\n",
    "    decoder_X = np.zeros(shape=(1, OUTPUT_LENGTH))\n",
    "    decoder_X[0,0] = START_INDEX\n",
    "    predictions = []\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        prediction = model.predict([encoder_X, decoder_X])[0][i].argmax()\n",
    "        predictions.append(prediction)\n",
    "        decoder_X[0,i] = prediction\n",
    "    pred_chars = []\n",
    "    for i in predictions:\n",
    "        if i == 0:\n",
    "            break\n",
    "        pred_chars += output_tokenizer.index_word[i]\n",
    "    return ''.join(pred_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a few cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. helmikuuta 2003 → 01.02.2003\n",
      "Toukokuun 7. päivä 1995 → 07.05.1995\n",
      "9. päivä huhtikuuta 2020 → 09.04.2020\n"
     ]
    }
   ],
   "source": [
    "test_inputs = ['1. helmikuuta 2003', 'Toukokuun 7. päivä 1995', '9. päivä huhtikuuta 2020']\n",
    "for text in test_inputs:\n",
    "    print(text, '→', predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coverage of the training data is not comprehensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tammikuuta vuonna 800 → 01.08.2001\n",
      "vuoden 2020 ensimmäinen päivä → 02.07.200\n"
     ]
    }
   ],
   "source": [
    "test_inputs = ['1. tammikuuta vuonna 800', 'vuoden 2020 ensimmäinen päivä']\n",
    "for text in test_inputs:\n",
    "    print(text, '→', predict(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
